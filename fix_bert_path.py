#!/usr/bin/env python3
"""
ä¿®æ”¹ GroundingDINO ä½¿ç”¨æœ¬åœ° BERT æ¨¡å‹

ç”¨æ³•ï¼š
    åœ¨æœåŠ¡å™¨ä¸Šè¿è¡Œï¼špython fix_bert_path.py
"""

import os
import shutil
from pathlib import Path

# é…ç½®è·¯å¾„
GROUNDINGDINO_DIR = Path("/root/autodl-tmp/model_zoo/bert")
GET_TOKENLIZER_FILE = GROUNDINGDINO_DIR / "groundingdino/util/get_tokenlizer.py"
LOCAL_BERT_PATH = "/root/navid_ws/pretrained_models/bert-base-uncased"

def backup_file(file_path):
    """å¤‡ä»½åŸå§‹æ–‡ä»¶"""
    backup_path = file_path.with_suffix(file_path.suffix + '.bak')
    if not backup_path.exists():
        shutil.copy2(file_path, backup_path)
        print(f"âœ… å·²å¤‡ä»½: {backup_path}")
    else:
        print(f"âš ï¸  å¤‡ä»½å·²å­˜åœ¨ï¼Œè·³è¿‡: {backup_path}")

def modify_get_tokenlizer():
    """ä¿®æ”¹ get_tokenlizer.py ä½¿ç”¨æœ¬åœ° BERT"""
    
    new_content = f'''# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved
from transformers import BertModel, BertTokenizer, RobertaModel, RobertaTokenizerFast
import os

# ========================================
# ğŸ”§ ä¿®æ”¹ï¼šä½¿ç”¨æœ¬åœ° BERT æ¨¡å‹
# ========================================
LOCAL_BERT_PATH = "{LOCAL_BERT_PATH}"


def get_pretrained_language_model(text_encoder_type):
    """
    åŠ è½½é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼ˆä¼˜å…ˆä½¿ç”¨æœ¬åœ°ï¼‰
    
    Args:
        text_encoder_type: æ¨¡å‹ç±»å‹ï¼Œå¦‚ "bert-base-uncased"
    
    Returns:
        é¢„è®­ç»ƒçš„è¯­è¨€æ¨¡å‹
    """
    if text_encoder_type == "bert-base-uncased":
        # æ£€æŸ¥æœ¬åœ°æ¨¡å‹æ˜¯å¦å­˜åœ¨
        if os.path.exists(LOCAL_BERT_PATH):
            print(f"âœ… [GroundingDINO] ä»æœ¬åœ°åŠ è½½ BERT: {{LOCAL_BERT_PATH}}")
            try:
                return BertModel.from_pretrained(LOCAL_BERT_PATH, local_files_only=True)
            except Exception as e:
                print(f"âš ï¸  [GroundingDINO] æœ¬åœ°æ¨¡å‹åŠ è½½å¤±è´¥: {{e}}")
                print(f"âš ï¸  [GroundingDINO] å°è¯•åœ¨çº¿ä¸‹è½½...")
                return BertModel.from_pretrained(text_encoder_type)
        else:
            print(f"âš ï¸  [GroundingDINO] æœ¬åœ°æ¨¡å‹ä¸å­˜åœ¨: {{LOCAL_BERT_PATH}}")
            print(f"âš ï¸  [GroundingDINO] å°è¯•åœ¨çº¿ä¸‹è½½: {{text_encoder_type}}")
            return BertModel.from_pretrained(text_encoder_type)
    
    if text_encoder_type == "roberta-base":
        return RobertaModel.from_pretrained(text_encoder_type)
    
    raise NotImplementedError(f"Unknown text encoder type: {{text_encoder_type}}")


def get_tokenlizer(text_encoder_type):
    """
    åŠ è½½ tokenizerï¼ˆä¼˜å…ˆä½¿ç”¨æœ¬åœ°ï¼‰
    
    Args:
        text_encoder_type: æ¨¡å‹ç±»å‹ï¼Œå¦‚ "bert-base-uncased"
    
    Returns:
        tokenizer
    """
    if text_encoder_type == "bert-base-uncased":
        # æ£€æŸ¥æœ¬åœ°æ¨¡å‹æ˜¯å¦å­˜åœ¨
        if os.path.exists(LOCAL_BERT_PATH):
            print(f"âœ… [GroundingDINO] ä»æœ¬åœ°åŠ è½½ Tokenizer: {{LOCAL_BERT_PATH}}")
            try:
                return BertTokenizer.from_pretrained(LOCAL_BERT_PATH, local_files_only=True)
            except Exception as e:
                print(f"âš ï¸  [GroundingDINO] æœ¬åœ° tokenizer åŠ è½½å¤±è´¥: {{e}}")
                print(f"âš ï¸  [GroundingDINO] å°è¯•åœ¨çº¿ä¸‹è½½...")
                return BertTokenizer.from_pretrained(text_encoder_type)
        else:
            print(f"âš ï¸  [GroundingDINO] æœ¬åœ° tokenizer ä¸å­˜åœ¨: {{LOCAL_BERT_PATH}}")
            print(f"âš ï¸  [GroundingDINO] å°è¯•åœ¨çº¿ä¸‹è½½: {{text_encoder_type}}")
            return BertTokenizer.from_pretrained(text_encoder_type)
    
    if text_encoder_type == "roberta-base":
        return RobertaTokenizerFast.from_pretrained(text_encoder_type)
    
    raise NotImplementedError(f"Unknown text encoder type: {{text_encoder_type}}")
'''
    
    return new_content

def verify_bert_model():
    """éªŒè¯ BERT æ¨¡å‹æ–‡ä»¶æ˜¯å¦å®Œæ•´"""
    bert_path = Path(LOCAL_BERT_PATH)
    
    required_files = [
        "config.json",
        "pytorch_model.bin",
        "tokenizer_config.json",
        "vocab.txt"
    ]
    
    print(f"\næ£€æŸ¥ BERT æ¨¡å‹: {bert_path}")
    
    if not bert_path.exists():
        print(f"âŒ æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {bert_path}")
        return False
    
    missing_files = []
    for file_name in required_files:
        file_path = bert_path / file_name
        if file_path.exists():
            size = file_path.stat().st_size
            print(f"  âœ… {file_name} ({size / 1024 / 1024:.1f} MB)")
        else:
            print(f"  âŒ {file_name} (ç¼ºå¤±)")
            missing_files.append(file_name)
    
    if missing_files:
        print(f"\nâŒ ç¼ºå°‘æ–‡ä»¶: {', '.join(missing_files)}")
        return False
    
    print(f"\nâœ… BERT æ¨¡å‹æ–‡ä»¶å®Œæ•´")
    return True

def main():
    print("=" * 60)
    print("ä¿®æ”¹ GroundingDINO ä½¿ç”¨æœ¬åœ° BERT æ¨¡å‹")
    print("=" * 60)
    
    # 1. æ£€æŸ¥ GroundingDINO æ˜¯å¦å­˜åœ¨
    print(f"\n[1/4] æ£€æŸ¥ GroundingDINO ç›®å½•...")
    if not GROUNDINGDINO_DIR.exists():
        print(f"âŒ é”™è¯¯: GroundingDINO ç›®å½•ä¸å­˜åœ¨: {GROUNDINGDINO_DIR}")
        return
    print(f"âœ… GroundingDINO ç›®å½•å­˜åœ¨")
    
    # 2. éªŒè¯ BERT æ¨¡å‹
    print(f"\n[2/4] éªŒè¯ BERT æ¨¡å‹...")
    if not verify_bert_model():
        print(f"\nâš ï¸  è­¦å‘Š: BERT æ¨¡å‹ä¸å®Œæ•´")
        print(f"è¯·ç¡®ä¿å·²ä¸‹è½½å¹¶è§£å‹æ¨¡å‹åˆ°: {LOCAL_BERT_PATH}")
        print(f"\néœ€è¦çš„æ–‡ä»¶:")
        print(f"  - config.json")
        print(f"  - pytorch_model.bin (çº¦ 440 MB)")
        print(f"  - tokenizer_config.json")
        print(f"  - vocab.txt")
        return
    
    # 3. å¤‡ä»½åŸå§‹æ–‡ä»¶
    print(f"\n[3/4] å¤‡ä»½åŸå§‹æ–‡ä»¶...")
    if not GET_TOKENLIZER_FILE.exists():
        print(f"âŒ é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨: {GET_TOKENLIZER_FILE}")
        return
    backup_file(GET_TOKENLIZER_FILE)
    
    # 4. ä¿®æ”¹æ–‡ä»¶
    print(f"\n[4/4] ä¿®æ”¹ get_tokenlizer.py...")
    new_content = modify_get_tokenlizer()
    
    with open(GET_TOKENLIZER_FILE, 'w', encoding='utf-8') as f:
        f.write(new_content)
    
    print(f"âœ… å·²ä¿®æ”¹: {GET_TOKENLIZER_FILE}")
    
    print(f"\n" + "=" * 60)
    print("âœ… ä¿®æ”¹å®Œæˆï¼")
    print("=" * 60)
    print(f"\nç°åœ¨å¯ä»¥è¿è¡Œæµ‹è¯•ç¨‹åº:")
    print(f"  cd /root/navid_ws/CA-Nav-code")
    print(f"  python minimal_mapping_test.py --exp-config vlnce_baselines/config/exp1.yaml")
    print(f"\nå¦‚æœéœ€è¦æ¢å¤åŸå§‹æ–‡ä»¶:")
    print(f"  mv {GET_TOKENLIZER_FILE}.bak {GET_TOKENLIZER_FILE}")

if __name__ == "__main__":
    main()
