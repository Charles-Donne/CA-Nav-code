import os
import pdb
import queue
import copy
import gzip
import json
import numpy as np
from tqdm import tqdm
from PIL import Image
from fastdtw import fastdtw
from typing import List, Any, Dict
from collections import defaultdict
from skimage.morphology import binary_closing
import inspect

import torch
from torch import Tensor
from torchvision import transforms

from habitat import Config, logger
from habitat_extensions.measures import NDTW
from habitat.core.simulator import Observations
from habitat_baselines.common.base_trainer import BaseTrainer
from habitat_baselines.common.environments import get_env_class
from habitat.sims.habitat_simulator.actions import HabitatSimActions
from habitat_baselines.common.baseline_registry import baseline_registry

from vlnce_baselines.utils.map_utils import *
from vlnce_baselines.map.value_map import ValueMap
from vlnce_baselines.map.history_map import HistoryMap
from vlnce_baselines.map.direction_map import DirectionMap
from vlnce_baselines.utils.data_utils import OrderedSet
from vlnce_baselines.map.mapping import Semantic_Mapping
from vlnce_baselines.models.Policy import FusionMapPolicy
from vlnce_baselines.common.env_utils import construct_envs
from vlnce_baselines.common.utils import gather_list_and_concat, get_device
from vlnce_baselines.map.semantic_prediction import GroundedSAM
from vlnce_baselines.common.constraints import ConstraintsMonitor
from vlnce_baselines.utils.constant import base_classes, map_channels

from pyinstrument import Profiler
import warnings
warnings.filterwarnings('ignore')


# å…¼å®¹ä¸åŒç‰ˆæœ¬çš„ scikit-image
def _binary_closing_compat(image, footprint):
    """å…¼å®¹ scikit-image æ—§ç‰ˆæœ¬çš„ binary_closing è°ƒç”¨"""
    sig = inspect.signature(binary_closing)
    if 'footprint' in sig.parameters:
        return binary_closing(image, footprint=footprint)
    else:
        # æ—§ç‰ˆæœ¬ä½¿ç”¨ selem å‚æ•°
        return binary_closing(image, selem=footprint)


@baseline_registry.register_trainer(name="ZS-Evaluator-mp")
class ZeroShotVlnEvaluatorMP(BaseTrainer):
    """é›¶æ ·æœ¬è§†è§‰è¯­è¨€å¯¼èˆªè¯„ä¼°å™¨ï¼ˆå¤šè¿›ç¨‹ç‰ˆæœ¬ï¼‰
    
    åŠŸèƒ½ï¼šåœ¨å¤šä¸ªGPUä¸Šå¹¶è¡Œè¯„ä¼°VLNä»»åŠ¡
    æ ¸å¿ƒæµç¨‹ï¼šç¯å¢ƒåˆå§‹åŒ– â†’ ç¯è§†æ¢ç´¢ â†’ å¯¼èˆªæ‰§è¡Œ â†’ æŒ‡æ ‡è®¡ç®—
    """
    def __init__(self, config: Config, segment_module=None, mapping_module=None) -> None:
        super().__init__()
        
        # GPU è®¾å¤‡é…ç½®
        self.device = get_device(config.TORCH_GPU_ID)
        torch.cuda.set_device(self.device)
        self.config = config
        
        # åœ°å›¾ç›¸å…³é…ç½®
        self.map_args = config.MAP
        self.visualize = config.MAP.VISUALIZE  # æ˜¯å¦å¯è§†åŒ–
        self.resolution = config.MAP.MAP_RESOLUTION  # åœ°å›¾åˆ†è¾¨ç‡ï¼ˆcm/pixelï¼‰
        self.keyboard_control = config.KEYBOARD_CONTROL  # æ˜¯å¦æ‰‹åŠ¨æ§åˆ¶
        self.width = config.TASK_CONFIG.SIMULATOR.RGB_SENSOR.WIDTH  # RGB å›¾åƒå®½åº¦
        self.height = config.TASK_CONFIG.SIMULATOR.RGB_SENSOR.HEIGHT  # RGB å›¾åƒé«˜åº¦
        self.max_step = config.TASK_CONFIG.ENVIRONMENT.MAX_EPISODE_STEPS  # æ¯ä¸ª episode æœ€å¤§æ­¥æ•°
        self.map_shape = (config.MAP.MAP_SIZE_CM // self.resolution,
                          config.MAP.MAP_SIZE_CM // self.resolution)  # åœ°å›¾å°ºå¯¸
        
        # å›¾åƒé¢„å¤„ç†
        self.trans = transforms.Compose([transforms.ToPILImage(), 
                                         transforms.Resize(
                                             (self.map_args.FRAME_HEIGHT, self.map_args.FRAME_WIDTH), 
                                             interpolation=Image.NEAREST)
                                        ])
        
        # çŠ¶æ€å˜é‡åˆå§‹åŒ–
        self.classes = []  # å½“å‰è¦æ£€æµ‹çš„ç±»åˆ«åˆ—è¡¨
        self.current_episode_id = None  # å½“å‰ episode ID
        self.current_detections = None  # å½“å‰æ£€æµ‹ç»“æœ
        self.map_channels = map_channels  # åœ°å›¾é€šé“æ•°ï¼ˆéšœç¢ç‰©ã€æ¢ç´¢åŒºåŸŸç­‰ï¼‰
        
        # å„ç§åœ°å›¾åˆå§‹åŒ–ï¼ˆå…¨é›¶ï¼‰
        self.floor = np.zeros(self.map_shape)  # åœ°æ¿åœ°å›¾
        self.one_step_floor = np.zeros(self.map_shape)  # å½“å‰æ­¥æ–°æ¢ç´¢çš„åœ°æ¿
        self.frontiers = np.zeros(self.map_shape)  # è¾¹ç•Œåœ°å›¾ï¼ˆæ¢ç´¢è¾¹ç¼˜ï¼‰
        self.traversible = np.zeros(self.map_shape)  # å¯ç©¿è¶ŠåŒºåŸŸ
        self.collision_map = np.zeros(self.map_shape)  # ç¢°æ’åœ°å›¾
        self.visited = np.zeros(self.map_shape)  # å·²è®¿é—®åŒºåŸŸ
        
        # çº¦æŸç›¸å…³é…ç½®
        self.base_classes = copy.deepcopy(base_classes)  # åŸºç¡€ç±»åˆ«ï¼ˆå¦‚ floor, wall ç­‰ï¼‰
        self.min_constraint_steps = config.EVAL.MIN_CONSTRAINT_STEPS  # æœ€å°çº¦æŸæ­¥æ•°
        self.max_constraint_steps = config.EVAL.MAX_CONSTRAINT_STEPS  # æœ€å¤§çº¦æŸæ­¥æ•°
    
    def _set_eval_config(self) -> None:
        """è®¾ç½®è¯„ä¼°é…ç½®ï¼ˆä¸»è¦æ˜¯è¿›ç¨‹å’Œè®¾å¤‡ä¿¡æ¯ï¼‰"""
        print("set eval configs")
        self.config.defrost()
        self.config.MAP.DEVICE = self.config.TORCH_GPU_ID
        self.config.MAP.HFOV = self.config.TASK_CONFIG.SIMULATOR.RGB_SENSOR.HFOV
        self.config.MAP.AGENT_HEIGHT = self.config.TASK_CONFIG.SIMULATOR.AGENT_0.HEIGHT
        self.config.MAP.NUM_ENVIRONMENTS = self.config.NUM_ENVIRONMENTS
        self.config.MAP.RESULTS_DIR = self.config.RESULTS_DIR
        self.world_size = self.config.world_size  # æ€»è¿›ç¨‹æ•°
        self.local_rank = self.config.local_rank  # å½“å‰è¿›ç¨‹ç¼–å·
        self.config.freeze()
        
    def _init_envs(self) -> None:
        """åˆå§‹åŒ– Habitat ä»¿çœŸç¯å¢ƒ"""
        print("start to initialize environments")

        self.envs = construct_envs(
            self.config, 
            get_env_class(self.config.ENV_NAME),
            auto_reset_done=False,
            episodes_allowed=self.config.TASK_CONFIG.DATASET.EPISODES_ALLOWED,  # åªåŠ è½½åˆ†é…ç»™è¯¥è¿›ç¨‹çš„ episodes
        )
        print(f"local rank: {self.local_rank}, num of episodes: {self.envs.number_of_episodes}")
        self.detected_classes = OrderedSet()  # è®°å½•å·²æ£€æµ‹åˆ°çš„æ‰€æœ‰ç±»åˆ«ï¼ˆå»é‡ï¼‰
        print("initializing environments finished!")
        
    def _collect_val_traj(self) -> None:
        """åŠ è½½çœŸå®è½¨è¿¹æ•°æ®ï¼ˆç”¨äºè®¡ç®— NDTW ç­‰æŒ‡æ ‡ï¼‰"""
        split = self.config.TASK_CONFIG.DATASET.SPLIT
        with gzip.open(self.config.TASK_CONFIG.TASK.NDTW.GT_PATH.format(split=split)) as f:
            gt_data = json.load(f)

        self.gt_data = gt_data
        
    def _calculate_metric(self, infos: List):
        """è®¡ç®—è¯„ä¼°æŒ‡æ ‡ï¼šSuccess, SPL, NDTW, SDTW ç­‰"""
        curr_eps = self.envs.current_episodes()
        info = infos[0]
        ep_id = curr_eps[0].episode_id
        
        # è·å–çœŸå®è·¯å¾„å’Œé¢„æµ‹è·¯å¾„
        gt_path = np.array(self.gt_data[str(ep_id)]['locations']).astype(np.float)
        pred_path = np.array(info['position']['position'])
        distances = np.array(info['position']['distance'])  # æ¯æ­¥åˆ°ç›®æ ‡çš„è·ç¦»
        gt_length = distances[0]  # èµ·ç‚¹åˆ°ç»ˆç‚¹çš„ç›´çº¿è·ç¦»
        
        # è®¡ç®— DTW è·ç¦»
        dtw_distance = fastdtw(pred_path, gt_path, dist=NDTW.euclidean_distance)[0]
        
        metric = {}
        metric['steps_taken'] = info['steps_taken']
        metric['distance_to_goal'] = distances[-1]  # æœ€ç»ˆè·ç¦»ç›®æ ‡çš„è·ç¦»
        metric['success'] = 1. if distances[-1] <= 3. else 0.  # Success: è·ç¦» â‰¤ 3 ç±³
        metric['oracle_success'] = 1. if (distances <= 3.).any() else 0.  # Oracle Success: ä»»æ„æ—¶åˆ»è·ç¦» â‰¤ 3 ç±³
        metric['path_length'] = float(np.linalg.norm(pred_path[1:] - pred_path[:-1],axis=1).sum())
        
        # SPL (Success weighted by Path Length)
        metric['spl'] = metric['success'] * gt_length / max(gt_length, metric['path_length'])
        
        # NDTW (Normalized Dynamic Time Warping)
        metric['ndtw'] = np.exp(-dtw_distance / (len(gt_path) * 3.))
        
        # SDTW (Success weighted by NDTW)
        metric['sdtw'] = metric['ndtw'] * metric['success']
        
        self.state_eps[ep_id] = metric
        print(self.state_eps[ep_id])
        
    def _initialize_policy(self) -> None:
        """åˆå§‹åŒ–æ‰€æœ‰ç­–ç•¥æ¨¡å—ï¼šè¯­ä¹‰åˆ†å‰²ã€åœ°å›¾æ„å»ºã€ä»·å€¼ä¼°è®¡ã€è·¯å¾„è§„åˆ’ç­‰"""
        print("start to initialize policy")
        
        # è¯­ä¹‰åˆ†å‰²æ¨¡å—ï¼ˆGroundedSAMï¼šå¼€æ”¾è¯æ±‡ç›®æ ‡æ£€æµ‹ï¼‰
        self.segment_module = GroundedSAM(self.config, self.device)
        
        # è¯­ä¹‰åœ°å›¾æ„å»ºæ¨¡å—
        self.mapping_module = Semantic_Mapping(self.config.MAP).to(self.device)
        self.mapping_module.eval()
        
        # ä»·å€¼åœ°å›¾æ¨¡å—ï¼ˆè®¡ç®—æ¯ä¸ªä½ç½®åˆ°ç›®æ ‡çš„ä»·å€¼ï¼‰
        self.value_map_module = ValueMap(self.config, self.mapping_module.map_shape, self.device)
        
        # å†å²åœ°å›¾æ¨¡å—ï¼ˆè®°å½•å·²è®¿é—®åŒºåŸŸï¼Œé¿å…é‡å¤æ¢ç´¢ï¼‰
        self.history_module = HistoryMap(self.config, self.mapping_module.map_shape)
        
        # æ–¹å‘åœ°å›¾æ¨¡å—ï¼ˆå¤„ç†æ–¹å‘çº¦æŸï¼Œå¦‚"å·¦è½¬"ï¼‰
        self.direction_module = DirectionMap(self.config, self.mapping_module.map_shape)
        
        # è·¯å¾„è§„åˆ’ç­–ç•¥ï¼ˆFMMï¼šFast Marching Methodï¼‰
        self.policy = FusionMapPolicy(self.config, self.mapping_module.map_shape[0])
        self.policy.reset()
        
        # çº¦æŸç›‘æ§æ¨¡å—ï¼ˆæ£€æŸ¥æ˜¯å¦æ»¡è¶³å­ä»»åŠ¡çº¦æŸï¼‰
        self.constraints_monitor = ConstraintsMonitor(self.config, self.device)
        
    def _concat_obs(self, obs: Observations) -> np.ndarray:
        """åˆå¹¶ RGB å’Œ Depth è§‚å¯Ÿä¸ºä¸€ä¸ªçŠ¶æ€"""
        rgb = obs['rgb'].astype(np.uint8)
        depth = obs['depth']
        state = np.concatenate((rgb, depth), axis=2).transpose(2, 0, 1) # (h, w, c)->(c, h, w)
        
        return state
    
    def _preprocess_state(self, state: np.ndarray) -> np.ndarray:
        """é¢„å¤„ç†çŠ¶æ€ï¼šè¯­ä¹‰åˆ†å‰² + æ·±åº¦å¤„ç† + ä¸‹é‡‡æ ·"""
        state = state.transpose(1, 2, 0)
        rgb = state[:, :, :3].astype(np.uint8) #[3, h, w]
        rgb = rgb[:,:,::-1] # RGB to BGRï¼ˆOpenCV æ ¼å¼ï¼‰
        depth = state[:, :, 3:4] #[1, h, w]
        min_depth = self.config.TASK_CONFIG.SIMULATOR.DEPTH_SENSOR.MIN_DEPTH
        max_depth = self.config.TASK_CONFIG.SIMULATOR.DEPTH_SENSOR.MAX_DEPTH
        env_frame_width = self.config.TASK_CONFIG.SIMULATOR.RGB_SENSOR.WIDTH
        
        # è¯­ä¹‰åˆ†å‰²é¢„æµ‹ï¼ˆGroundedSAMï¼‰
        sem_seg_pred = self._get_sem_pred(rgb) #[num_detected_classes, h, w]
        
        # æ·±åº¦é¢„å¤„ç†ï¼ˆå½’ä¸€åŒ–ã€å»å™ªï¼‰
        depth = self._preprocess_depth(depth, min_depth, max_depth) #[1, h, w]
        
        # ä¸‹é‡‡æ ·å› å­ï¼ˆ640 / 160 = 4ï¼‰
        ds = env_frame_width // self.map_args.FRAME_WIDTH # ds = 4
        if ds != 1:
            rgb = np.asarray(self.trans(rgb.astype(np.uint8))) # resize
            depth = depth[ds // 2::ds, ds // 2::ds] # down scaling start from 2, step=4
            sem_seg_pred = sem_seg_pred[ds // 2::ds, ds // 2::ds]

        depth = np.expand_dims(depth, axis=2) # recover depth.shape to (height, width, 1)
        state = np.concatenate((rgb, depth, sem_seg_pred),axis=2).transpose(2, 0, 1) # (4+num_detected_classes, h, w)
        
        return state
        
    def _get_sem_pred(self, rgb: np.ndarray) -> np.ndarray:
        """ä½¿ç”¨ GroundedSAM è¿›è¡Œè¯­ä¹‰åˆ†å‰²
        
        è¿”å›ï¼š
            masks: [num_detected_classes, h, w] æ¯ä¸ªç±»åˆ«çš„æ©ç 
        """
        masks, labels, annotated_images, self.current_detections = \
            self.segment_module.segment(rgb, classes=self.classes)
        self.mapping_module.rgb_vis = annotated_images
        assert len(masks) == len(labels), f"The number of masks not equal to the number of labels!"
        print("current step detected classes: ", labels)  # ä¾‹å¦‚: ["kitchen counter 0.69", "floor 0.37"]
        
        # å¤„ç†æ ‡ç­¾ï¼ˆå»æ‰ç½®ä¿¡åº¦åˆ†æ•°ï¼‰
        class_names = self._process_labels(labels)
        
        # å¤„ç†æ©ç ï¼ˆåˆå¹¶ç›¸åŒç±»åˆ«ï¼‰
        masks = self._process_masks(masks, class_names)
        
        return masks.transpose(1, 2, 0)
    
    def _process_labels(self, labels: List[str]) -> List:
        """å¤„ç†æ ‡ç­¾ï¼šå»é™¤ç½®ä¿¡åº¦åˆ†æ•°ï¼Œè®°å½•åˆ°å·²æ£€æµ‹ç±»åˆ«é›†åˆ"""
        class_names = []
        for label in labels:
            # "kitchen counter 0.69" -> "kitchen counter"
            class_name = " ".join(label.split(' ')[:-1])
            class_names.append(class_name)
            self.detected_classes.add(class_name)  # æ·»åŠ åˆ°å·²æ£€æµ‹ç±»åˆ«ï¼ˆè‡ªåŠ¨å»é‡ï¼‰
        
        return class_names
        
    def _process_masks(self, masks: np.ndarray, labels: List[str]):
        """å¤„ç†æ©ç ï¼šåˆå¹¶ç›¸åŒç±»åˆ«çš„æ©ç ï¼Œæ„å»ºåŠ¨æ€é€šé“çš„æ©ç å¼ é‡
        
        ç”±äºæ˜¯å¼€æ”¾è¯æ±‡è¯­ä¹‰æ˜ å°„ï¼Œéœ€è¦ç»´æŠ¤ä¸€ä¸ªåŠ¨æ€é€šé“çš„æ©ç å¼ é‡ã€‚
        å°†æ‰€æœ‰ç›¸åŒç±»åˆ«çš„æ©ç åˆå¹¶ä¸ºä¸€ä¸ªé€šé“ã€‚
        
        Args:
            masks: shape (c, h, w)ï¼Œæ¯ä¸ªå®ä¾‹ä¸€ä¸ªé€šé“
            labels: å¯¹åº”çš„æ ‡ç­¾åˆ—è¡¨
            
        Returns:
            final_masks: shape (len(detected_classes), h, w)
        """
        if masks.shape != (0,):
            # æŒ‰ç±»åˆ«åˆ†ç»„
            same_label_indexs = defaultdict(list)
            for idx, item in enumerate(labels):
                same_label_indexs[item].append(idx) #dict {class name: [idx]}
            
            # åˆå¹¶åŒç±»æ©ç 
            combined_mask = np.zeros((len(same_label_indexs), *masks.shape[1:]))
            for i, indexs in enumerate(same_label_indexs.values()):
                combined_mask[i] = np.sum(masks[indexs, ...], axis=0)
            
            # æ‰¾åˆ°æ¯ä¸ªç±»åˆ«åœ¨ detected_classes ä¸­çš„ç´¢å¼•
            idx = [self.detected_classes.index(label) for label in same_label_indexs.keys()]
            
            # æ„å»ºæœ€ç»ˆæ©ç ï¼ˆç»´åº¦ = æ‰€æœ‰å·²æ£€æµ‹ç±»åˆ«æ•°ï¼‰
            final_masks = np.zeros((len(self.detected_classes), *masks.shape[1:]))
            final_masks[idx, ...] = combined_mask
        else:
            final_masks = np.zeros((len(self.detected_classes), self.height, self.width))
        
        return final_masks
    
    def _preprocess_depth(self, depth: np.ndarray, min_depth: float, max_depth: float) -> np.ndarray:
        """é¢„å¤„ç†æ·±åº¦å›¾ï¼šå¤„ç†ç¼ºå¤±å€¼ã€å»é™¤å¼‚å¸¸å€¼ã€å½’ä¸€åŒ–"""
        depth = depth[:, :, 0] * 1

        # å¡«å……ç¼ºå¤±æ·±åº¦å€¼
        for i in range(depth.shape[1]):
            depth[:, i][depth[:, i] == 0.] = depth[:, i].max()

        # å°†è¿‡è¿œçš„åƒç´ è®¾ä¸ºæ— æ•ˆ
        mask2 = depth > 0.99
        depth[mask2] = 0.

        # å°†æ— æ•ˆåƒç´ è®¾ä¸ºè§†é‡èŒƒå›´ï¼ˆ100ç±³ï¼‰
        mask1 = depth == 0
        depth[mask1] = 100.0
        
        # å½’ä¸€åŒ–åˆ°å˜ç±³å•ä½
        depth = min_depth * 100.0 + depth * max_depth * 100.0
        
        return depth
    
    def _preprocess_obs(self, obs: np.ndarray) -> np.ndarray:
        """é¢„å¤„ç†è§‚å¯Ÿï¼šåˆå¹¶ + é¢„å¤„ç†"""
        concated_obs = self._concat_obs(obs)
        state = self._preprocess_state(concated_obs)
        
        return state # state.shape=(c,h,w)
    
    def _batch_obs(self, n_obs: List[Observations]) -> Tensor:
        """æ‰¹å¤„ç†è§‚å¯Ÿï¼ˆæ”¯æŒåŠ¨æ€é€šé“æ•°ï¼Œpadding åˆ°æœ€å¤§é€šé“æ•°ï¼‰"""
        n_states = [self._preprocess_obs(obs) for obs in n_obs]
        max_channels = max([len(state) for state in n_states])
        batch = np.stack([np.pad(state, 
                [(0, max_channels - state.shape[0]), 
                 (0, 0), 
                 (0, 0)], 
                mode='constant') 
         for state in n_states], axis=0)
        
        # ç¡®ä¿è¿”å› float32 ç±»å‹ï¼Œé¿å… depth_utils ä¸­çš„ç±»å‹ä¸åŒ¹é…é—®é¢˜
        return torch.from_numpy(batch).float().to(self.device)
    
    def _random_policy(self):
        """éšæœºç­–ç•¥ï¼ˆç”¨äºæµ‹è¯•ï¼‰"""
        action = np.random.choice([
            HabitatSimActions.MOVE_FORWARD,
            HabitatSimActions.TURN_LEFT,
            HabitatSimActions.TURN_RIGHT,
        ])
        
        return {"action": action}

    def _process_classes(self, base_class: List, target_class: List) -> List:
        """å¤„ç†ç±»åˆ«åˆ—è¡¨ï¼šç§»é™¤é‡å¤çš„ç›®æ ‡ç±»åˆ«ï¼Œç„¶åæ·»åŠ åˆ°æœ«å°¾"""
        for item in target_class:
            if item in base_class:
                base_class.remove(item)
        base_class.extend(target_class)
        
        return base_class
    
    def _check_destination(self, current_idx: int, sub_constraints: dict, llm_destination: str, decisions: dict) -> str:
        for idx in range(current_idx, len(sub_constraints)):
                constraints = sub_constraints[str(idx)]
                landmarks = decisions[str(idx)]["landmarks"]
                for constraint in constraints:
                    if constraint[0] == "direction constraint":
                        continue
                    else:
                        landmark = constraint[1]
                        for item in landmarks:
                            print(landmark, item)
                            if landmark in item:
                                choice = item[1]
                            else:
                                continue
                            print(choice, choice != "move away")
                            if choice != "move away":
                                return constraint[1]
                            else:
                                break
        else:
            return llm_destination
    
    def _process_llm_reply(self, obs: Observations):
        """è§£æ LLM ç”Ÿæˆçš„æŒ‡ä»¤åˆ†è§£ç»“æœ
        
        LLM è¾“å‡ºåŒ…å«ï¼š
        - sub-instructions: å­æŒ‡ä»¤åˆ—è¡¨
        - state-constraints: æ¯ä¸ªå­æŒ‡ä»¤çš„çº¦æŸæ¡ä»¶
        - decisions: æ¯ä¸ªå­æŒ‡ä»¤çš„å†³ç­– landmarks
        - destination: æœ€ç»ˆç›®æ ‡
        """
        def _get_first_destination(sub_constraints: dict, llm_destination: str) -> str:
            """è·å–ç¬¬ä¸€ä¸ªç›®æ ‡ï¼ˆç¬¬ä¸€ä¸ªéæ–¹å‘çº¦æŸçš„ landmarkï¼‰"""
            for constraints in sub_constraints.values():
                for constraint in constraints:
                    if constraint[0] != "direction constraint":
                        return constraint[1]
            else:
                return llm_destination
        
        
        self.llm_reply = obs['llm_reply']
        self.instruction = obs['instruction']['text']  # åŸå§‹æŒ‡ä»¤
        self.sub_instructions = self.llm_reply['sub-instructions']  # å­æŒ‡ä»¤åˆ—è¡¨
        self.sub_constraints = self.llm_reply['state-constraints']  # çº¦æŸæ¡ä»¶
        self.decisions = self.llm_reply['decisions']  # å†³ç­– landmarks
        self.destination = _get_first_destination(self.sub_constraints, self.llm_reply['destination'])  # å½“å‰ç›®æ ‡
        print("!!!!!!!!!!!!!!! first destination: ", self.destination)
        
        self.last_destination = self.destination  # ä¸Šä¸€ä¸ªç›®æ ‡
        first_landmarks = self.decisions['0']['landmarks']  # ç¬¬ä¸€ä¸ªå­ä»»åŠ¡çš„ landmarks
        self.destination_class = [item[0] for item in first_landmarks]  # ç›®æ ‡ç±»åˆ«åˆ—è¡¨
        self.classes = self._process_classes(self.base_classes, self.destination_class)  # æ›´æ–°æ£€æµ‹ç±»åˆ«
        self.constraints_check = [False] * len(self.sub_constraints)  # çº¦æŸæ£€æŸ¥çŠ¶æ€ï¼ˆæœªå®Œæˆï¼‰
    
    
    def _process_one_step_floor(self, one_step_full_map: np.ndarray, kernel_size: int=3) -> np.ndarray:
        """å¤„ç†å½“å‰æ­¥æ–°æ¢ç´¢çš„åœ°æ¿åŒºåŸŸ"""
        navigable_index = process_navigable_classes(self.detected_classes)
        not_navigable_index = [i for i in range(len(self.detected_classes)) if i not in navigable_index]
        one_step_full_map = remove_small_objects(one_step_full_map.astype(bool), min_size=64)
        
        obstacles = one_step_full_map[0, ...].astype(bool)
        explored_area = one_step_full_map[1, ...].astype(bool)
        objects = np.sum(one_step_full_map[map_channels:, ...][not_navigable_index], axis=0).astype(bool)
        navigable = np.logical_or.reduce(one_step_full_map[map_channels:, ...][navigable_index])
        navigable = np.logical_and(navigable, np.logical_not(objects))
        
        free_mask = 1 - np.logical_or(obstacles, objects)
        free_mask = np.logical_or(free_mask, navigable)
        floor = explored_area * free_mask
        floor = remove_small_objects(floor, min_size=400).astype(bool)
        floor = _binary_closing_compat(floor, disk(kernel_size))
        
        return floor
        
    def _process_map(self, step: int, full_map: np.ndarray, kernel_size: int=3) -> tuple:
        """å¤„ç†è¯­ä¹‰åœ°å›¾ï¼Œæå–å¯¼èˆªç›¸å…³ä¿¡æ¯
        
        Returns:
            traversible: å¯ç©¿è¶ŠåŒºåŸŸ
            floor: åœ°æ¿åŒºåŸŸ
            frontiers: è¾¹ç•ŒåŒºåŸŸï¼ˆæ¢ç´¢è¾¹ç¼˜ï¼‰
        """
        # åŒºåˆ†å¯å¯¼èˆªå’Œä¸å¯å¯¼èˆªçš„ç±»åˆ«
        navigable_index = process_navigable_classes(self.detected_classes)
        not_navigable_index = [i for i in range(len(self.detected_classes)) if i not in navigable_index]
        full_map = remove_small_objects(full_map.astype(bool), min_size=64)
        
        # æå–åœ°å›¾é€šé“
        obstacles = full_map[0, ...].astype(bool)  # éšœç¢ç‰©
        explored_area = full_map[1, ...].astype(bool)  # å·²æ¢ç´¢åŒºåŸŸ
        objects = np.sum(full_map[map_channels:, ...][not_navigable_index], axis=0).astype(bool)  # ä¸å¯å¯¼èˆªç‰©ä½“
        
        # å½¢æ€å­¦å¤„ç†ï¼ˆé—­è¿ç®—ï¼Œå¡«å……å°å­”ï¼‰
        footprint = disk(kernel_size)
        obstacles_closed = _binary_closing_compat(obstacles, footprint)
        objects_closed = _binary_closing_compat(objects, footprint)
        navigable = np.logical_or.reduce(full_map[map_channels:, ...][navigable_index])
        navigable = np.logical_and(navigable, np.logical_not(objects))
        navigable_closed = _binary_closing_compat(navigable, footprint)
        
        # è®¡ç®—ä¸å¯ç©¿è¶ŠåŒºåŸŸ
        untraversible = np.logical_or(objects_closed, obstacles_closed)
        untraversible[navigable_closed == 1] = 0
        untraversible = remove_small_objects(untraversible, min_size=64)
        untraversible = _binary_closing_compat(untraversible, disk(3))
        traversible = np.logical_not(untraversible)

        # è®¡ç®—åœ°æ¿åŒºåŸŸ
        free_mask = 1 - np.logical_or(obstacles, objects)
        free_mask = np.logical_or(free_mask, navigable)
        floor = explored_area * free_mask
        floor = remove_small_objects(floor, min_size=400).astype(bool)
        floor = _binary_closing_compat(floor, footprint)
        traversible = np.logical_or(floor, traversible)
        
        # è®¡ç®—è¾¹ç•Œï¼ˆæ¢ç´¢è¾¹ç¼˜ï¼‰
        explored_area = _binary_closing_compat(explored_area, footprint)
        contours, _ = cv2.findContours(explored_area.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        image = np.zeros(full_map.shape[-2:], dtype=np.uint8)
        image = cv2.drawContours(image, contours, -1, (255, 255, 255), thickness=3)
        frontiers = np.logical_and(floor, image)
        frontiers = remove_small_objects(frontiers.astype(bool), min_size=64)

        return traversible, floor, frontiers.astype(np.uint8)
    
    def _save_floor_semantic_map(self, step: int, episode_id: int, full_map: np.ndarray):
        """ä¿å­˜åŒ…å«floorè¯­ä¹‰å±‚çš„åˆ†å‰²åœ°å›¾å¯è§†åŒ–
        
        Args:
            step: å½“å‰æ­¥æ•°
            episode_id: episode ID
            full_map: å®Œæ•´è¯­ä¹‰åœ°å›¾ (N+1, 480, 480)
        """
        # æå–å„é€šé“
        obstacles = full_map[0, ...].astype(bool)     # éšœç¢ç‰©ï¼ˆçº¯å‡ ä½•ï¼Œé«˜åº¦>æ™ºèƒ½ä½“ï¼‰
        explored = full_map[1, ...].astype(bool)      # å·²æ¢ç´¢
        current_loc = full_map[2, ...].astype(bool)   # å½“å‰ä½ç½®
        
        # åˆ›å»ºå½©è‰²å¯è§†åŒ– (480, 480, 3)
        h, w = obstacles.shape
        vis_image = np.zeros((h, w, 3), dtype=np.uint8)
        
        # é¢œè‰²æ–¹æ¡ˆï¼š
        # - ç™½è‰² (255,255,255): æœªæ¢ç´¢åŒºåŸŸ
        # - æµ…ç°è‰² (200,200,200): å·²æ¢ç´¢çš„ç©ºåœ°ï¼ˆæ— éšœç¢æ— ç‰©ä½“ï¼‰
        # - é»‘è‰² (0,0,0): éšœç¢ç‰©ï¼ˆé«˜åº¦åˆ¤æ–­ï¼Œå¢™ä½“ç­‰ï¼‰
        # - æµ…ç»¿è‰² (144,238,144): floorè¯­ä¹‰å±‚ï¼ˆå¯è¡Œèµ°åœ°æ¿ï¼‰
        # - çº¢/è“/é»„/ç´«ç­‰: å„ç§è¯­ä¹‰ç‰©ä½“ï¼ˆtable, chair, kitchenç­‰ï¼‰
        
        # 1. æœªæ¢ç´¢åŒºåŸŸ = ç™½è‰²ï¼ˆé»˜è®¤èƒŒæ™¯ï¼‰
        vis_image[:] = [255, 255, 255]
        
        # 2. å·²æ¢ç´¢åŒºåŸŸ = æµ…ç°è‰²
        vis_image[explored] = [200, 200, 200]
        
        # 3. å…ˆç»˜åˆ¶æ‰€æœ‰è¯­ä¹‰ç‰©ä½“ï¼ˆå½©è‰²ï¼‰
        if full_map.shape[0] > 4:  # æœ‰è¯­ä¹‰é€šé“
            semantic_channels = full_map[4:, ...]  # æ‰€æœ‰è¯­ä¹‰é€šé“
            
            # ä¸ºæ¯ä¸ªæ£€æµ‹ç±»åˆ«åˆ†é…ç‹¬ç‰¹é¢œè‰²
            color_palette = [
                [255, 0, 0],      # 0: çº¢è‰² (å¦‚ table)
                [0, 0, 255],      # 1: è“è‰² (å¦‚ chair)
                [255, 255, 0],    # 2: é»„è‰² (å¦‚ bed)
                [255, 0, 255],    # 3: å“çº¢ (å¦‚ sofa)
                [0, 255, 255],    # 4: é’è‰² (å¦‚ cabinet)
                [255, 128, 0],    # 5: æ©™è‰² (å¦‚ counter)
                [128, 0, 255],    # 6: ç´«è‰² (å¦‚ sink)
                [0, 128, 255],    # 7: å¤©è“ (å¦‚ refrigerator)
                [255, 128, 128],  # 8: ç²‰çº¢
                [128, 255, 128],  # 9: æµ…ç»¿ï¼ˆæ³¨æ„å’ŒflooråŒºåˆ†ï¼‰
                [128, 128, 255],  # 10: æµ…è“
                [255, 255, 128],  # 11: æµ…é»„
            ]
            
            # ç»˜åˆ¶æ¯ä¸ªæ£€æµ‹åˆ°çš„è¯­ä¹‰ç±»åˆ«
            for i, class_name in enumerate(self.detected_classes):
                if i >= semantic_channels.shape[0]:
                    break
                class_mask = semantic_channels[i] > 0.5  # ç½®ä¿¡åº¦é˜ˆå€¼
                if np.any(class_mask):
                    color = color_palette[i % len(color_palette)]
                    vis_image[class_mask] = color
        
        # 4. Floorè¯­ä¹‰å±‚ = æµ…ç»¿è‰² (144,238,144) Light Green
        floor_overlay = self.floor.astype(bool)
        vis_image[floor_overlay] = [144, 238, 144]
        
        # 5. éšœç¢ç‰©ï¼ˆçº¯å‡ ä½•é«˜åº¦åˆ¤æ–­ï¼‰= é»‘è‰²ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
        vis_image[obstacles] = [0, 0, 0]
        
        # ç¿»è½¬å›¾åƒï¼ˆä¸å…¶ä»–åœ°å›¾å¯è§†åŒ–ä¿æŒä¸€è‡´ï¼‰
        vis_image = np.flipud(vis_image)
        
        # 6. ç»˜åˆ¶å½“å‰ä½ç½®å’Œæœå‘ç®­å¤´
        # æ‰¾åˆ°å½“å‰ä½ç½®çš„ä¸­å¿ƒç‚¹
        current_loc_flipped = np.flipud(current_loc)
        if np.any(current_loc_flipped):
            # è·å–å½“å‰ä½ç½®çš„è´¨å¿ƒ
            y_coords, x_coords = np.where(current_loc_flipped)
            if len(y_coords) > 0:
                center_y = int(np.mean(y_coords))
                center_x = int(np.mean(x_coords))
                
                # ä»full_poseè·å–æœå‘è§’åº¦
                # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦ä»self.mapping_moduleè·å–å½“å‰ä½å§¿
                if hasattr(self, 'mapping_module') and hasattr(self.mapping_module, 'full_pose'):
                    heading = self.mapping_module.full_pose[0, -1]  # å¼§åº¦
                    
                    # è®¡ç®—ç®­å¤´ç»ˆç‚¹ï¼ˆç®­å¤´é•¿åº¦ä¸º20åƒç´ ï¼‰
                    arrow_length = 20
                    # Habitatåæ ‡ç³»ï¼šheading=0æœå‘+Xè½´ï¼ˆåœ°å›¾å³ä¾§ï¼‰
                    # OpenCVåæ ‡ç³»ï¼šéœ€è¦è½¬æ¢ï¼Œyè½´å‘ä¸‹
                    end_x = int(center_x + arrow_length * np.cos(heading))
                    end_y = int(center_y - arrow_length * np.sin(heading))  # yè½´åå‘
                    
                    # ç»˜åˆ¶ç®­å¤´ï¼ˆçº¢è‰²ï¼Œç²—çº¿ï¼‰
                    cv2.arrowedLine(
                        vis_image,
                        (center_x, center_y),  # èµ·ç‚¹
                        (end_x, end_y),        # ç»ˆç‚¹
                        (0, 0, 255),           # çº¢è‰²ç®­å¤´
                        thickness=3,           # çº¿å®½
                        tipLength=0.3          # ç®­å¤´å°–ç«¯é•¿åº¦æ¯”ä¾‹
                    )
                    
                    # ç»˜åˆ¶ä¸­å¿ƒç‚¹ï¼ˆé»„è‰²åœ†ç‚¹ï¼Œæ›´é†’ç›®ï¼‰
                    cv2.circle(vis_image, (center_x, center_y), 5, (0, 255, 255), -1)
        
        # ä¿å­˜å›¾åƒ
        save_dir = os.path.join(self.config.RESULTS_DIR, "floor_semantic_map/eps_%d" % episode_id)
        os.makedirs(save_dir, exist_ok=True)
        fn = "{}/step-{}.png".format(save_dir, step)
        cv2.imwrite(fn, vis_image)
    
    def _maps_initialization(self):
        """åˆå§‹åŒ–åœ°å›¾ï¼šé‡ç½®ç¯å¢ƒ + è§£ææŒ‡ä»¤ + åˆå§‹åŒ–è¯­ä¹‰åœ°å›¾"""
        obs = self.envs.reset()  # é‡ç½®ç¯å¢ƒï¼Œè·å–åˆå§‹è§‚å¯Ÿ
        self._process_llm_reply(obs[0])  # è§£æ LLM æŒ‡ä»¤
        self.current_episode_id = self.envs.current_episodes()[0].episode_id
        print("current episode id: ", self.current_episode_id)
        
        # åˆå§‹åŒ–è¯­ä¹‰åœ°å›¾
        self.mapping_module.init_map_and_pose(num_detected_classes=len(self.detected_classes))
        batch_obs = self._batch_obs(obs)
        poses = torch.from_numpy(np.array([item['sensor_pose'] for item in obs])).float().to(self.device)
        self.mapping_module(batch_obs, poses)
        full_map, full_pose, _ = self.mapping_module.update_map(0, self.detected_classes, self.current_episode_id)
        
        # æ¸…ç©ºå•æ­¥åœ°å›¾
        self.mapping_module.one_step_full_map.fill_(0.)
        self.mapping_module.one_step_local_map.fill_(0.)
    
    def _look_around(self):
        """ç¯è§† 360 åº¦ï¼ˆ12 æ­¥ Ã— 30Â° = 360Â°ï¼‰ï¼Œå»ºç«‹åˆå§‹åœ°å›¾
        
        æ ¸å¿ƒæµç¨‹ï¼š
        1. å¾ªç¯ 12 æ¬¡ï¼Œæ¯æ¬¡å·¦è½¬ 30Â° (12 Ã— 30Â° = 360Â°)
        2. æ¯æ¬¡è½¬å‘åï¼š
           - è·å– RGB-D è§‚å¯Ÿ
           - è¯­ä¹‰åˆ†å‰²ï¼ˆGroundedSAMï¼‰
           - ç‚¹äº‘ç”Ÿæˆ + åæ ‡å˜æ¢
           - 3D ä½“ç´ æŠ•å½± + é«˜åº¦å‹ç¼©
           - å¤šå¸§èåˆï¼ˆå–æœ€å¤§å€¼ï¼‰
           - æ›´æ–°å…¨å±€åœ°å›¾
        3. ç¯è§†ç»“æŸåè§„åˆ’åˆå§‹åŠ¨ä½œ
        
        Returns:
            full_pose: (3,) [x, y, heading] å½“å‰ä½å§¿ï¼ˆç±³ï¼‰
            obs: dict æœ€åä¸€å¸§è§‚å¯Ÿ
            dones: bool episode æ˜¯å¦ç»“æŸ
            infos: dict é™„åŠ ä¿¡æ¯
        """
        print("\n========== LOOK AROUND ==========\n")
        # åˆå§‹åŒ–è¿”å›å˜é‡
        full_pose, obs, dones, infos = None, None, None, None
        
        # ========== å¾ªç¯ 12 æ¬¡ï¼Œæ¯æ¬¡å·¦è½¬ 30Â° ==========
        for step in range(0, 12):
            # ===== æ­¥éª¤ 1: æ‰§è¡Œå·¦è½¬åŠ¨ä½œ (30Â°) =====
            actions = []
            for _ in range(self.config.NUM_ENVIRONMENTS):
                # HabitatSimActions.TURN_LEFT = å·¦è½¬ 30Â°
                actions.append({"action": HabitatSimActions.TURN_LEFT})
            
            # åœ¨ä»¿çœŸç¯å¢ƒä¸­æ‰§è¡ŒåŠ¨ä½œ
            outputs = self.envs.step(actions)
            
            # è§£åŒ…ç»“æœ: obs=è§‚å¯Ÿ, _=å¥–åŠ±(ä¸ä½¿ç”¨), dones=æ˜¯å¦ç»“æŸ, infos=é™„åŠ ä¿¡æ¯
            obs, _, dones, infos = [list(x) for x in zip(*outputs)]
            
            # Save RGB frames if print_images is enabled
            if self.config.MAP.PRINT_IMAGES:
                rgb_frame = obs[0]['rgb'].astype(np.uint8)  # Get RGB from observation
                save_dir = os.path.join(self.config.RESULTS_DIR, "rgb_frames/eps_%d"%self.current_episode_id)
                os.makedirs(save_dir, exist_ok=True)
                fn = "{}/step-{}.png".format(save_dir, step)
                # Convert RGB to BGR for OpenCV
                bgr_frame = cv2.cvtColor(rgb_frame, cv2.COLOR_RGB2BGR)
                cv2.imwrite(fn, bgr_frame)
            
            # ===== æ­¥éª¤ 2: æ£€æŸ¥ episode æ˜¯å¦æå‰ç»“æŸ =====
            if dones[0]:
                # å¦‚æœå·²ç»“æŸï¼ˆä¾‹å¦‚è¶…æ—¶ã€ç¢°æ’ç­‰ï¼‰ï¼Œç›´æ¥è¿”å›
                return full_pose, obs, dones, infos
            
            # ===== æ­¥éª¤ 3: æ›´æ–°è¯­ä¹‰åœ°å›¾ï¼ˆæ ¸å¿ƒå»ºå›¾æµç¨‹ï¼‰=====
            
            # 3.1 é¢„å¤„ç†è§‚å¯Ÿ â†’ è¯­ä¹‰åˆ†å‰²
            # Line 517: æ‰¹å¤„ç†è§‚å¯Ÿ â†’ è¯­ä¹‰åˆ†å‰²
            batch_obs = self._batch_obs(obs)
            # â†“ å±•å¼€è°ƒç”¨é“¾ï¼š
            # _batch_obs() [Line 346]
            #   â†’ _preprocess_obs() [Line 349]
            #     â†’ _concat_obs() [Line 203] åˆå¹¶ RGB + Depth
            #     â†’ _preprocess_state() [Line 210]
            #       â†’ _get_sem_pred() [Line 220] ğŸ”¥ GroundedSAM è¯­ä¹‰åˆ†å‰²
            #         â†’ segment_module.segment() [GroundedSAM]
            #           è¿”å›: masks (N, 480, 640)
            #       â†’ _preprocess_depth() [Line 313]
            #       â†’ ä¸‹é‡‡æ · 4x
            #   è¿”å›: batch_obs (1, 4+N, 160, 160)
            
            # 3.2 è·å–æ™ºèƒ½ä½“ä½å§¿å˜åŒ– (ç›¸å¯¹äºä¸Šä¸€æ­¥çš„ä½ç§»)
            # sensor_pose: [Î”x, Î”y, Î”Î¸] å•ä½: ç±³, ç±³, å¼§åº¦
            poses = torch.from_numpy(np.array([item['sensor_pose'] for item in obs])).float().to(self.device)
            
            # 3.3 è°ƒç”¨ mapping_module å‰å‘ä¼ æ’­ï¼ˆæ ¸å¿ƒå»ºå›¾ï¼‰
            # mapping_module.forward() æ‰§è¡Œ:
            #   â‘  ç‚¹äº‘ç”Ÿæˆ: Depth â†’ (120, 160, 3) 3D ç‚¹
            #   â‘¡ åæ ‡å˜æ¢: ç›¸æœºåæ ‡ç³» â†’ æ™ºèƒ½ä½“åæ ‡ç³» â†’ ä¸–ç•Œåæ ‡ç³»
            #   â‘¢ ä½“ç´ æŠ•å½±: ç‚¹äº‘ + è¯­ä¹‰ç‰¹å¾ â†’ (N+1, 100, 100, 80) 3D ä½“ç´ 
            #   â‘£ é«˜åº¦å‹ç¼©: æ²¿ z è½´æ±‚å’Œ â†’ (N+1, 100, 100) 2D åœ°å›¾
            #   â‘¤ ä½å§¿å˜æ¢: agent_view â†’ æ—‹è½¬ + å¹³ç§» â†’ local_map
            #   â‘¥ å¤šå¸§èåˆ: max(å†å²åœ°å›¾, å½“å‰å¸§) â†’ æ›´æ–° local_map
            self.mapping_module(batch_obs, poses)
            
            # 3.4 æ›´æ–°å…¨å±€åœ°å›¾å¹¶è·å–å½“å‰çŠ¶æ€
            # update_map() æ‰§è¡Œ:
            #   â‘  æ›´æ–°å½“å‰ä½ç½®æ ‡è®° (3Ã—3 åŒºåŸŸ)
            #   â‘¡ local_map â†’ full_map (å†™å›åˆ°å…¨å±€åœ°å›¾)
            #   â‘¢ æ›´æ–°å…¨å±€ä½å§¿
            # è¿”å›:
            #   full_map: (1, N+4, 480, 480) å®Œæ•´è¯­ä¹‰åœ°å›¾
            #     é€šé“ 0: éšœç¢ç‰©åœ°å›¾
            #     é€šé“ 1: å·²æ¢ç´¢åŒºåŸŸ
            #     é€šé“ 2: å½“å‰ä½ç½®
            #     é€šé“ 3: å·²è®¿é—®åŒºåŸŸ
            #     é€šé“ 4~: å„ç±»åˆ«è¯­ä¹‰æ©ç  (å¦‚ floor, wall, kitchen ç­‰)
            #   full_pose: (1, 3) [x, y, heading] å½“å‰å…¨å±€ä½å§¿ï¼ˆç±³ï¼‰
            #   one_step_full_map: (1, N+4, 480, 480) ä»…åŒ…å«å½“å‰å¸§çš„åœ°å›¾
            full_map, full_pose, one_step_full_map = \
                self.mapping_module.update_map(step, self.detected_classes, self.current_episode_id)
            
            # 3.5 æ¸…ç©ºå•æ­¥åœ°å›¾ï¼ˆå‡†å¤‡ä¸‹ä¸€æ¬¡å¾ªç¯ï¼‰
            # one_step_*_map åªè®°å½•å½“å‰å¸§ï¼Œæ¯æ­¥éƒ½æ¸…ç©º
            # ç”¨é€”: åŒºåˆ†"æ–°æ¢ç´¢åŒºåŸŸ" vs "å†å²ç´¯ç§¯åŒºåŸŸ"
            self.mapping_module.one_step_full_map.fill_(0.)
            self.mapping_module.one_step_local_map.fill_(0.)
            
            # ===== æ­¥éª¤ 4: å¤„ç†å¯¼èˆªåœ°å›¾ï¼ˆæå–å¯å¯¼èˆªä¿¡æ¯ï¼‰=====
            
            # 4.1 ä»è¯­ä¹‰åœ°å›¾ä¸­æå–å¯¼èˆªç›¸å…³ä¿¡æ¯
            # _process_map() æ‰§è¡Œ:
            #   â‘  åŒºåˆ†å¯å¯¼èˆªç±»åˆ« (floor, carpet) å’Œä¸å¯å¯¼èˆªç±»åˆ« (wall, table)
            #   â‘¡ å½¢æ€å­¦å¤„ç† (é—­è¿ç®—å¡«å……å°å­”)
            #   â‘¢ è®¡ç®—å¯ç©¿è¶ŠåŒºåŸŸ traversible
            #   â‘£ è®¡ç®—åœ°æ¿åŒºåŸŸ floor
            #   â‘¤ è®¡ç®—æ¢ç´¢è¾¹ç•Œ frontiers (å·²æ¢ç´¢åŒºåŸŸçš„è½®å»“)
            # è¿”å›:
            #   traversible: (480, 480) bool å¯ç©¿è¶ŠåŒºåŸŸ
            #   floor: (480, 480) bool åœ°æ¿åŒºåŸŸ
            #   frontiers: (480, 480) uint8 æ¢ç´¢è¾¹ç•Œ
            self.traversible, self.floor, self.frontiers = self._process_map(step, full_map[0])
            
            # Save floor map visualization if print_images is enabled
            if self.config.MAP.PRINT_IMAGES:
                self._save_floor_semantic_map(step, self.current_episode_id, full_map[0])
            
            # 4.2 å¤„ç†å½“å‰æ­¥æ–°æ¢ç´¢çš„åœ°æ¿
            # åªå¤„ç† one_step_full_mapï¼Œç”¨äºä»·å€¼å›¾è®¡ç®—
            self.one_step_floor = self._process_one_step_floor(one_step_full_map[0])
                        
            # ===== æ­¥éª¤ 5: è®¡ç®—ä»·å€¼å›¾ï¼ˆç›®æ ‡å¯¼å‘çš„ä»·å€¼åˆ†å¸ƒï¼‰=====
            
            # 5.1 ä½¿ç”¨ BLIP è®¡ç®—å½“å‰è§†é‡ä¸ç›®æ ‡çš„è¯­ä¹‰ç›¸ä¼¼åº¦
            # BLIP (Bootstrapped Language-Image Pre-training):
            #   è¾“å…¥: RGB å›¾åƒ (480, 640, 3) + ç›®æ ‡æ–‡æœ¬ (å¦‚ "kitchen")
            #   è¾“å‡º: blip_value (160, 160) æ¯ä¸ªåƒç´ ä¸ç›®æ ‡çš„ç›¸ä¼¼åº¦ [0, 1]
            # åŸç†: è§†è§‰-è¯­è¨€å¯¹æ¯”å­¦ä¹ ï¼Œè®¡ç®—å›¾åƒåŒºåŸŸä¸æ–‡æœ¬æè¿°çš„åŒ¹é…åº¦
            blip_value = self.value_map_module.get_blip_value(
                Image.fromarray(obs[0]['rgb']),  # å½“å‰ RGB è§‚å¯Ÿ
                self.destination                 # ç›®æ ‡æè¿° (å¦‚ "kitchen", "living room")
            )
            blip_value = blip_value.detach().cpu().numpy()
            
            # 5.2 èåˆå¤šç§ä¿¡æ¯ç”Ÿæˆä»·å€¼å›¾
            # value_map_module() æ‰§è¡Œ:
            #   â‘  å°† blip_value æŠ•å½±åˆ°åœ°å›¾åæ ‡ç³» (160Ã—160 â†’ 480Ã—480)
            #   â‘¡ ç»“åˆè¯­ä¹‰é€šé“ (ç›®æ ‡ç±»åˆ«çš„æ©ç ï¼Œå¦‚ "kitchen" é€šé“)
            #   â‘¢ åº”ç”¨è·ç¦»è¡°å‡ (ç¦»ç›®æ ‡è¶Šè¿œä»·å€¼è¶Šä½)
            #   â‘£ æ’é™¤ç¢°æ’åŒºåŸŸ (ä»·å€¼ç½®é›¶)
            #   â‘¤ èåˆæ–°æ¢ç´¢åŒºåŸŸå¥–åŠ± (é¼“åŠ±æ¢ç´¢)
            # è¿”å›: value_map (2, 480, 480)
            #   [0]: åŸå§‹ä»·å€¼å›¾
            #   [1]: å¤„ç†åä»·å€¼å›¾ (ä¼šåœ¨åç»­ä¹˜ä»¥ history_map å’Œ direction_map)
            value_map = self.value_map_module(
                step,                    # å½“å‰æ­¥æ•°
                full_map[0],            # å®Œæ•´è¯­ä¹‰åœ°å›¾ (N+4, 480, 480)
                self.floor,             # åœ°æ¿åŒºåŸŸ (480, 480)
                self.one_step_floor,    # å½“å‰æ­¥æ–°æ¢ç´¢åœ°æ¿ (480, 480)
                self.collision_map,     # ç¢°æ’åœ°å›¾ (480, 480)
                blip_value,             # BLIP ç›¸ä¼¼åº¦ (160, 160)
                full_pose[0],           # å½“å‰ä½å§¿ [x, y, heading]
                self.detected_classes,  # å·²æ£€æµ‹ç±»åˆ«åˆ—è¡¨
                self.current_episode_id # å½“å‰ episode ID (ç”¨äºå¯è§†åŒ–)
            )
        
        # ========== ç¯è§†ç»“æŸï¼šè§„åˆ’åˆå§‹åŠ¨ä½œ ==========
        
        # ä½¿ç”¨ FMM (Fast Marching Method) è·¯å¾„è§„åˆ’ç®—æ³•
        # policy() æ‰§è¡Œ:
        #   â‘  å°†ä»·å€¼å›¾ä½œä¸ºç›®æ ‡åœº (é«˜ä»·å€¼åŒºåŸŸ = ç›®æ ‡)
        #   â‘¡ FMM æ‰©æ•£ç®—æ³•è®¡ç®—è·ç¦»åœº (æ¯ä¸ªä½ç½®åˆ°é«˜ä»·å€¼åŒºåŸŸçš„è·ç¦»)
        #   â‘¢ æ¢¯åº¦ä¸‹é™æ‰¾åˆ°æœ€ä¼˜è·¯å¾„
        #   â‘£ æ ¹æ®è·¯å¾„æ–¹å‘ç”ŸæˆåŠ¨ä½œ
        # è¿”å›: {"action": 0/1/2/3} 
        #   0=STOP, 1=FORWARD, 2=TURN_LEFT, 3=TURN_RIGHT
        self._action = self.policy(
            self.value_map_module.value_map[1],  # ä»·å€¼å›¾ (480, 480)
            self.collision_map,                  # ç¢°æ’åœ°å›¾ (480, 480)
            full_map[0],                        # å®Œæ•´è¯­ä¹‰åœ°å›¾ (N+4, 480, 480)
            self.floor,                         # åœ°æ¿åŒºåŸŸ (480, 480)
            self.traversible,                   # å¯ç©¿è¶ŠåŒºåŸŸ (480, 480)
            full_pose[0],                       # å½“å‰ä½å§¿ [x, y, heading]
            self.frontiers,                     # æ¢ç´¢è¾¹ç•Œ (480, 480)
            self.detected_classes,              # å·²æ£€æµ‹ç±»åˆ«åˆ—è¡¨
            self.destination_class,             # ç›®æ ‡ç±»åˆ«åˆ—è¡¨ (å¦‚ ["kitchen"])
            self.classes,                       # å½“å‰è¦æ£€æµ‹çš„ç±»åˆ«åˆ—è¡¨
            False,                              # search_destination: æ˜¯å¦æœç´¢æœ€ç»ˆç›®æ ‡
            one_step_full_map[0],              # å½“å‰å¸§åœ°å›¾ (N+4, 480, 480)
            self.current_detections,            # å½“å‰æ£€æµ‹ç»“æœ (ç”¨äºç›®æ ‡éªŒè¯)
            self.current_episode_id,            # episode ID (ç”¨äºå¯è§†åŒ–)
            False,                              # replan: æ˜¯å¦å¼ºåˆ¶é‡æ–°è§„åˆ’
            step                                # å½“å‰æ­¥æ•°
        )
        
        # è¿”å›æœ€ç»ˆçŠ¶æ€
        return full_pose, obs, dones, infos
    
    def _use_keyboard_control(self):
        """æ‰‹åŠ¨é”®ç›˜æ§åˆ¶ï¼ˆç”¨äºè°ƒè¯•ï¼‰"""
        a = input("action:")
        if a == 'w':
           return {"action": 1}  # å‰è¿›
        elif a == 'a':
            return {"action": 2}  # å·¦è½¬
        elif a == 'd':
            return {"action": 3}  # å³è½¬
        else:
            return {"action": 0}  # åœæ­¢
    
    def reset(self) -> None:
        """é‡ç½®æ‰€æœ‰çŠ¶æ€ï¼Œå‡†å¤‡ä¸‹ä¸€ä¸ª episode"""
        self.classes = []
        self.current_detections = None
        self.detected_classes = OrderedSet()
        self.floor = np.zeros(self.map_shape)
        self.one_step_floor = np.zeros(self.map_shape)
        self.frontiers = np.zeros(self.map_shape)
        self.traversible = np.zeros(self.map_shape)
        self.collision_map = np.zeros(self.map_shape)
        self.visited = np.zeros(self.map_shape)
        self.base_classes = copy.deepcopy(base_classes)
        
        # é‡ç½®æ‰€æœ‰æ¨¡å—
        self.policy.reset()
        self.mapping_module.reset()
        self.value_map_module.reset()
        self.history_module.reset()
    
    def rollout(self):
        """æ‰§è¡Œä¸€ä¸ªå®Œæ•´çš„ episodeï¼ˆåŒ…å«å¤šä¸ªå­ä»»åŠ¡ï¼‰
        
        è¿™æ˜¯ VLN ä»»åŠ¡çš„æ ¸å¿ƒæ‰§è¡Œå‡½æ•°ï¼Œå¤„ç†ä»åˆå§‹åŒ–åˆ°å®Œæˆçš„æ•´ä¸ªå¯¼èˆªè¿‡ç¨‹ã€‚
        æ”¯æŒå¤æ‚çš„è‡ªç„¶è¯­è¨€æŒ‡ä»¤ï¼Œé€šè¿‡å­ä»»åŠ¡åˆ†è§£ã€çº¦æŸç›‘æ§ã€ä»·å€¼å›¾èåˆç­‰æœºåˆ¶
        å®ç°é²æ£’çš„å®¤å†…å¯¼èˆªã€‚
        
        ä¸»è¦æµç¨‹ï¼š
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ 1. åˆå§‹åŒ–åœ°å›¾ (_maps_initialization)   â”‚
        â”‚    - é‡ç½®ç¯å¢ƒ                           â”‚
        â”‚    - è§£æ LLM æŒ‡ä»¤                      â”‚
        â”‚    - åˆå§‹åŒ–è¯­ä¹‰åœ°å›¾                     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ 2. ç¯è§†å»ºå›¾ (_look_around)             â”‚
        â”‚    - æ—‹è½¬ 360Â° (12 æ­¥ Ã— 30Â°)           â”‚
        â”‚    - è¯­ä¹‰åˆ†å‰² + åœ°å›¾æ„å»º                â”‚
        â”‚    - è§„åˆ’åˆå§‹åŠ¨ä½œ                       â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ 3. ä¸»å¯¼èˆªå¾ªç¯ (æ­¥æ•° 12-500)            â”‚
        â”‚    â”œâ”€ æ›´æ–°è½¨è¿¹ç‚¹                        â”‚
        â”‚    â”œâ”€ è®¡ç®—å†å²/æ–¹å‘çº¦æŸåœ°å›¾             â”‚
        â”‚    â”œâ”€ æ£€æŸ¥å­ä»»åŠ¡çº¦æŸ                    â”‚
        â”‚    â”œâ”€ åˆ‡æ¢å­ä»»åŠ¡ï¼ˆå¦‚éœ€è¦ï¼‰              â”‚
        â”‚    â”œâ”€ æ‰§è¡ŒåŠ¨ä½œ                          â”‚
        â”‚    â”œâ”€ æ›´æ–°è¯­ä¹‰åœ°å›¾                      â”‚
        â”‚    â”œâ”€ ç¢°æ’æ£€æµ‹ä¸å¼‚å¸¸æ¢å¤                â”‚
        â”‚    â”œâ”€ è®¡ç®—ä»·å€¼å›¾ï¼ˆBLIPï¼‰                â”‚
        â”‚    â””â”€ FMM è·¯å¾„è§„åˆ’                      â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        
        çº¦æŸç®¡ç†çŠ¶æ€æœºï¼š
        EXECUTING â†’ (çº¦æŸæ»¡è¶³) â†’ WAITING â†’ (æœ€å°æ­¥æ•°) â†’ SWITCH_TASK
        
        å¼‚å¸¸æ¢å¤æœºåˆ¶ï¼š
        - è¿ç»­ç¢°æ’ 30 æ­¥ â†’ é‡æ–°è§„åˆ’ (replan=True)
        - ä»·å€¼å›¾ç©º 5 æ¬¡ â†’ é‡æ–°ç¯è§† 360Â°
        - è¶…è¿‡æœ€å¤§çº¦æŸæ­¥æ•° â†’ å¼ºåˆ¶åˆ‡æ¢ä¸‹ä¸€å­ä»»åŠ¡
        
        Returns:
            None (ç»“æœé€šè¿‡ self._calculate_metric è®°å½•)
        """
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # é˜¶æ®µ 1: åˆå§‹åŒ–ä¸ç¯è§†å»ºå›¾
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        
        # åˆå§‹åŒ–è¯­ä¹‰åœ°å›¾ï¼Œè§£æ LLM æŒ‡ä»¤åˆ†è§£ç»“æœ
        # è°ƒç”¨: envs.reset() â†’ _process_llm_reply() â†’ mapping_module.init_map_and_pose()
        self._maps_initialization()
        
        # ç¯è§† 360Â° å»ºç«‹åˆå§‹åœ°å›¾ (12 æ­¥ Ã— 30Â° = 360Â°)
        # è¿”å›: å½“å‰ä½å§¿ã€è§‚å¯Ÿã€ç»“æŸæ ‡å¿—ã€é™„åŠ ä¿¡æ¯
        full_pose, obs, dones, infos = self._look_around()
        print("\n ========== START TO NAVIGATE ==========\n")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # é˜¶æ®µ 2: åˆå§‹åŒ–å¯¼èˆªçŠ¶æ€å˜é‡
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        
        # --- è½¨è¿¹è¿½è¸ª ---
        trajectory_points = []  # å­˜å‚¨æœ€è¿‘ 2 ä¸ªä½ç½®ç‚¹ [(y1,x1), (y2,x2)]
                                # ç”¨é€”: HistoryMap æ¨¡å—ï¼Œé¿å…åŸåœ°å¾˜å¾Š
                                # åœ¨ä»·å€¼å›¾ä¸Šé™ä½å·²è®¿é—®åŒºåŸŸçš„ä»·å€¼
        
        direction_points = []   # å­˜å‚¨æœ€è¿‘ 5 ä¸ªä½ç½®ç‚¹ [array([x1,y1]), ...]
                                # ç”¨é€”: DirectionMap æ¨¡å—ï¼Œå¤„ç†æ–¹å‘çº¦æŸ
                                # ä¾‹å¦‚æŒ‡ä»¤"turn left"æ—¶ï¼Œæ£€æŸ¥ç§»åŠ¨æ–¹å‘å‘é‡
        
        # --- çº¦æŸç®¡ç† ---
        constraint_steps = 0    # å½“å‰å­ä»»åŠ¡å·²æ‰§è¡Œçš„æ­¥æ•°è®¡æ•°å™¨
                                # ç”¨é€”: åˆ¤æ–­æ˜¯å¦è¾¾åˆ°åˆ‡æ¢å­ä»»åŠ¡çš„æ¡ä»¶
                                # èŒƒå›´: [MIN_CONSTRAINT_STEPS, MAX_CONSTRAINT_STEPS]
        
        start_to_wait = False   # çº¦æŸæ»¡è¶³åçš„ç­‰å¾…æ ‡å¿—
                                # True: çº¦æŸå·²æ»¡è¶³ï¼Œç­‰å¾…æœ€å°æ­¥æ•°ååˆ‡æ¢
                                # False: æ­£åœ¨æ‰§è¡Œçº¦æŸ
        
        search_destination = False  # æ˜¯å¦åˆ°è¾¾æœ€åä¸€ä¸ªå­ä»»åŠ¡æ ‡å¿—
                                    # True: å¼€å§‹æœç´¢æœ€ç»ˆç›®æ ‡ä½ç½®
                                    # False: è¿˜åœ¨æ‰§è¡Œä¸­é—´å­ä»»åŠ¡
        
        # --- å¼‚å¸¸æ¢å¤ ---
        collided = 0            # è¿ç»­ç¢°æ’/å¡ä½çš„æ­¥æ•°è®¡æ•°å™¨
                                # â‰¥30: è§¦å‘é‡æ–°è§„åˆ’ (replan=True)
                                # <0.2m/æ­¥ åˆ¤å®šä¸ºå¡ä½
        
        empty_value_map = 0     # ä»·å€¼å›¾ä¸ºç©ºçš„è¿ç»­æ¬¡æ•°
                                # â‰¥5: è§¦å‘é‡æ–°ç¯è§† 360Â°
                                # â‰¤24Ã—24 åƒç´ åˆ¤å®šä¸ºç©º
        
        replan = False          # æ˜¯å¦éœ€è¦é‡æ–°è§„åˆ’è·¯å¾„æ ‡å¿—
                                # True: ä¼ é€’ç»™ policyï¼Œå¼ºåˆ¶é‡æ–°è®¡ç®—è·¯å¾„
        
        # --- æ–¹å‘çº¦æŸ ---
        direction_map = np.ones(self.map_shape)  # (480, 480) æ–¹å‘çº¦æŸæ©ç 
                                                 # å…¨1: æ— æ–¹å‘é™åˆ¶
                                                 # éƒ¨åˆ†0: å±è”½ä¸ç¬¦åˆæ–¹å‘çš„åŒºåŸŸ
        
        direction_map_exist = False  # æ–¹å‘åœ°å›¾æ˜¯å¦å·²è®¡ç®—æ ‡å¿—
                                     # é¿å…é‡å¤è®¡ç®—ç›¸åŒçš„æ–¹å‘çº¦æŸ
        
        # --- ä½å§¿è¿½è¸ª ---
        last_action = None      # ä¸Šä¸€æ­¥æ‰§è¡Œçš„åŠ¨ä½œ {"action": 0/1/2/3}
        current_action = None   # å½“å‰æ­¥æ‰§è¡Œçš„åŠ¨ä½œ
                                # ç”¨é€”: åªåœ¨ FORWARD åŠ¨ä½œæ—¶æ›´æ–°ç¢°æ’åœ°å›¾
        
        last_pose = None        # ä¸Šä¸€æ­¥çš„ä½å§¿ [x, y, Î¸]
        current_pose = full_pose[0]  # å½“å‰ä½å§¿ [x, y, Î¸] (ç±³, ç±³, å¼§åº¦)
                                     # ç”¨é€”: è®¡ç®—ä½ç§»ï¼Œæ£€æµ‹æ˜¯å¦å¡ä½
        
        start_check_pose = None # å¼€å§‹æ£€æŸ¥æ–¹å‘çº¦æŸæ—¶çš„ä½å§¿
                                # ç”¨é€”: è®¡ç®—ä»èµ·å§‹ä½ç½®è½¬è¿‡çš„è§’åº¦
        
        self._action2 = None    # é”®ç›˜æ‰‹åŠ¨æ§åˆ¶åŠ¨ä½œ (è°ƒè¯•ç”¨)
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # é˜¶æ®µ 3: è·å–ç¬¬ä¸€ä¸ªå­ä»»åŠ¡ä¿¡æ¯
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        
        # æ‰¾åˆ°ç¬¬ä¸€ä¸ªæœªå®Œæˆçš„å­ä»»åŠ¡ç´¢å¼• (åˆå§‹å…¨ä¸º Falseï¼Œè¿”å› 0)
        current_idx = self.constraints_check.index(False)
        
        # è·å–è¯¥å­ä»»åŠ¡çš„ landmark å†³ç­–
        # ä¾‹å¦‚: [("kitchen", "move towards"), ("table", "move away")]
        landmarks = self.decisions[str(current_idx)]['landmarks']
        
        # æå–ç›®æ ‡ç±»åˆ«åç§° (å»æ‰å†³ç­–åŠ¨ä½œ)
        # ä¾‹å¦‚: ["kitchen", "table"]
        self.destination_class = [item[0] for item in landmarks]
        
        # æ›´æ–°éœ€è¦æ£€æµ‹çš„ç±»åˆ«åˆ—è¡¨ (åŸºç¡€ç±»åˆ« + ç›®æ ‡ç±»åˆ«)
        # base_classes: ["floor", "wall", "door", ...] (å¸¸è§å®¤å†…ç‰©ä½“)
        # ç›®æ ‡ç±»åˆ«ä¼šè¢«ç§»åˆ°åˆ—è¡¨æœ«å°¾ï¼Œæé«˜æ£€æµ‹ä¼˜å…ˆçº§
        self.classes = self._process_classes(self.base_classes, self.destination_class)
        
        # è·å–å½“å‰å­ä»»åŠ¡çš„çº¦æŸæ¡ä»¶
        # ä¾‹å¦‚: [("direction constraint", "turn left"), ("landmark constraint", "kitchen")]
        current_constraint = self.sub_constraints[str(current_idx)]
        
        # æå–çº¦æŸç±»å‹åˆ—è¡¨
        # ä¾‹å¦‚: ["direction constraint", "landmark constraint"]
        all_constraint_types = [item[0] for item in current_constraint]
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # é˜¶æ®µ 4: ä¸»å¯¼èˆªå¾ªç¯ (æ­¥æ•° 12-500)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        for step in range(12, self.max_step):
            # â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            # â”‚ 4.1 æ‰“å°å½“å‰çŠ¶æ€ (è°ƒè¯•ä¿¡æ¯)                                 â”‚
            # â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            print(f"\nepisode:{self.current_episode_id}, step:{step}")
            print(f"instr: {self.instruction}")  # å®Œæ•´æŒ‡ä»¤
            print(f"sub_instr_{current_idx}: {self.sub_instructions[current_idx]}")  # å½“å‰å­æŒ‡ä»¤
            
            # çº¦æŸæ­¥æ•°è®¡æ•°å™¨é€’å¢
            constraint_steps += 1
            
            # â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            # â”‚ 4.2 æ›´æ–°ä½ç½®å’Œè½¨è¿¹è®°å½•                                       â”‚
            # â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            
            # å°†ä½å§¿ä»ç±³è½¬æ¢ä¸ºåƒç´ åæ ‡
            # full_pose[0][:2] = [x_m, y_m] â†’ position = [x_px, y_px]
            position = full_pose[0][:2] * 100 / self.resolution  # ç±³ â†’ å˜ç±³ â†’ åƒç´ 
            heading = full_pose[0][-1]  # æœå‘è§’åº¦ (å¼§åº¦)
            print("full pose: ", full_pose[0])  # [x, y, Î¸] (ç±³, ç±³, å¼§åº¦)
            
            # è½¬æ¢åæ ‡å¹¶é™åˆ¶åœ¨åœ°å›¾èŒƒå›´å†…
            # æ³¨æ„: position[0]=x, position[1]=yï¼Œä½†åœ°å›¾åæ ‡æ˜¯ (y, x)
            y = min(int(position[0]), self.map_shape[0] - 1)  # é™åˆ¶ 0~479
            x = min(int(position[1]), self.map_shape[1] - 1)  # é™åˆ¶ 0~479
            
            # æ ‡è®°å½“å‰ä½ç½®ä¸ºå·²è®¿é—®
            self.visited[x, y] = 1
            
            # æ›´æ–°è½¨è¿¹ç‚¹åˆ—è¡¨ (ç”¨äºå†å²åœ°å›¾)
            trajectory_points.append((y, x))
            if len(trajectory_points) > 2:
                del trajectory_points[0]  # ä¿æŒæœ€å¤š 2 ä¸ªç‚¹: [å‰ä¸€æ­¥, å½“å‰æ­¥]
            
            # æ›´æ–°æ–¹å‘ç‚¹åˆ—è¡¨ (ç”¨äºæ–¹å‘çº¦æŸ)
            direction_points.append(np.array([x, y]))
            if len(direction_points) > 5:
                del direction_points[0]  # ä¿æŒæœ€å¤š 5 ä¸ªç‚¹ï¼Œè®¡ç®—ç§»åŠ¨è¶‹åŠ¿
            
            # â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            # â”‚ 4.3 è®¡ç®—å†å²åœ°å›¾ (é¿å…åŸåœ°å¾˜å¾Š)                              â”‚
            # â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            # HistoryMap: åœ¨æœ€è¿‘è®¿é—®çš„åŒºåŸŸç»˜åˆ¶æƒ©ç½šå€¼
            # åŸç†: è¿æ¥ trajectory_points çš„ä¸¤ä¸ªç‚¹ï¼Œç”»ä¸€æ¡ç›´çº¿
            #       åœ¨ç›´çº¿å‘¨å›´åŒºåŸŸçš„ä»·å€¼å›¾ä¸Šä¹˜ä»¥è¡°å‡ç³»æ•° (å¦‚ 0.5)
            # æ•ˆæœ: æ™ºèƒ½ä½“å€¾å‘äºæ¢ç´¢æ–°åŒºåŸŸï¼Œè€ŒéåŸè·¯è¿”å›
            history_map = self.history_module(trajectory_points, step, self.current_episode_id)

            # â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            # â”‚ 4.4 æ–¹å‘çº¦æŸå¤„ç†                                             â”‚
            # â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            # å¦‚æœæœ‰æ–¹å‘çº¦æŸ (å¦‚ "turn left")ï¼Œè®°å½•èµ·å§‹ä½å§¿ç”¨äºè§’åº¦è®¡ç®—
            if "direction constraint" in all_constraint_types and start_check_pose is None:
                start_check_pose = full_pose[0]  # è®°å½•å¼€å§‹æ£€æŸ¥æ—¶çš„ä½å§¿
            
            # æ£€æŸ¥æ˜¯å¦åˆ°è¾¾æœ€åä¸€ä¸ªå­ä»»åŠ¡
            if int(current_idx) >= len(self.sub_instructions) - 1:
                search_destination = True  # å¼€å§‹æœç´¢æœ€ç»ˆç›®æ ‡
                print("start to search destination")
                

            # â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            # â”‚ 4.5 çº¦æŸæ£€æŸ¥å’Œå­ä»»åŠ¡åˆ‡æ¢ (çŠ¶æ€æœºæ ¸å¿ƒé€»è¾‘)                    â”‚
            # â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            # åªåœ¨è¿˜æœ‰æœªå®Œæˆçš„å­ä»»åŠ¡æ—¶æ‰§è¡Œ
            if sum(self.constraints_check) < len(self.sub_instructions):
                
                # â”ˆâ”ˆâ”ˆâ”ˆâ”ˆ 4.5.1 è®¡ç®—æ–¹å‘çº¦æŸåœ°å›¾ â”ˆâ”ˆâ”ˆâ”ˆâ”ˆ
                # å¦‚æœå½“å‰çº¦æŸåŒ…å«æ–¹å‘çº¦æŸä¸”å°šæœªè®¡ç®—
                if (len(current_constraint) > 0 
                    and current_constraint[0][0] == "direction constraint" 
                    and not direction_map_exist):
                    
                    # æå–æ–¹å‘ç±»å‹ (å¦‚ "turn left", "turn right", "go straight")
                    direction = current_constraint[0][1]
                    
                    # è·å–å½“å‰ä½ç½®å’Œ 5 æ­¥å‰çš„ä½ç½® (ç”¨äºè®¡ç®—ç§»åŠ¨å‘é‡)
                    if len(direction_points) < 5:
                        # æ­¥æ•°ä¸è¶³ï¼Œä½¿ç”¨å½“å‰ä½ç½®
                        current_position = direction_points[-1]
                        last_five_position = direction_points[-1]
                    else:
                        # ä½¿ç”¨æœ€è¿‘ 5 æ­¥çš„é¦–å°¾ä½ç½®
                        current_position = direction_points[-1]      # å½“å‰
                        last_five_position = direction_points[0]     # 5æ­¥å‰
                    
                    # è°ƒç”¨ DirectionMap æ¨¡å—è®¡ç®—æ–¹å‘æ©ç 
                    # åŸç†: æ ¹æ®ç§»åŠ¨å‘é‡å’Œæœå‘è§’ï¼Œåˆ¤æ–­æ˜¯å¦æ»¡è¶³æ–¹å‘è¦æ±‚
                    #   - "turn left": å±è”½å³ä¾§å’Œæ­£å‰æ–¹åŒºåŸŸ
                    #   - "turn right": å±è”½å·¦ä¾§å’Œæ­£å‰æ–¹åŒºåŸŸ
                    #   - "go straight": å±è”½å·¦å³ä¸¤ä¾§åŒºåŸŸ
                    direction_map = self.direction_module(
                        current_position, last_five_position, heading,
                        direction, step, self.current_episode_id
                    )
                    direction_map_exist = True  # æ ‡è®°å·²è®¡ç®—
                else:
                    # æ— æ–¹å‘çº¦æŸï¼Œåœ°å›¾å…¨ä¸º 1 (ä¸é™åˆ¶)
                    direction_map = np.ones(self.map_shape)
                
                # â”ˆâ”ˆâ”ˆâ”ˆâ”ˆ 4.5.2 æ£€æŸ¥çº¦æŸæ˜¯å¦æ»¡è¶³ â”ˆâ”ˆâ”ˆâ”ˆâ”ˆ
                # ConstraintsMonitor: æ£€æŸ¥æ¯ä¸ªçº¦æŸæ¡ä»¶
                # è¿”å›: [True, False, True, ...] å¸ƒå°”åˆ—è¡¨
                # çº¦æŸç±»å‹:
                #   - "direction constraint": æ£€æŸ¥è½¬å‘è§’åº¦
                #   - "landmark constraint": æ£€æŸ¥æ˜¯å¦çœ‹åˆ°ç›®æ ‡ç‰©ä½“
                #   - "distance constraint": æ£€æŸ¥ä¸landmarkçš„è·ç¦»
                check = self.constraints_monitor(
                    current_constraint,       # å½“å‰çº¦æŸåˆ—è¡¨
                    obs[0],                   # å½“å‰è§‚å¯Ÿ
                    self.current_detections,  # å½“å‰æ£€æµ‹åˆ°çš„ç‰©ä½“
                    self.classes,             # æ£€æµ‹ç±»åˆ«åˆ—è¡¨
                    current_pose,             # å½“å‰ä½å§¿
                    start_check_pose          # å¼€å§‹æ£€æŸ¥æ—¶çš„ä½å§¿
                )
                print(current_constraint, check)  # è°ƒè¯•: æ‰“å°çº¦æŸå’Œæ£€æŸ¥ç»“æœ
                
                # â”ˆâ”ˆâ”ˆâ”ˆâ”ˆ 4.5.3 å¤„ç†æ–¹å‘çº¦æŸæ»¡è¶³ â”ˆâ”ˆâ”ˆâ”ˆâ”ˆ
                # å¦‚æœæ–¹å‘çº¦æŸå·²æ»¡è¶³ï¼Œé‡ç½®æ–¹å‘åœ°å›¾ (è§£é™¤é™åˆ¶)
                if (len(current_constraint) > 0 
                    and current_constraint[0][0] == "direction constraint" 
                    and check[0] == True):
                    direction_map = np.ones(self.map_shape)
                    direction_map_exist = False  # å…è®¸ä¸‹æ¬¡é‡æ–°è®¡ç®—
                
                # â”ˆâ”ˆâ”ˆâ”ˆâ”ˆ 4.5.4 æ›´æ–°æœªæ»¡è¶³çš„çº¦æŸ â”ˆâ”ˆâ”ˆâ”ˆâ”ˆ
                if len(check) == 0:
                    # ç©ºçº¦æŸåˆ—è¡¨
                    print("empty constraint")
                elif sum(check) < len(check):
                    # éƒ¨åˆ†çº¦æŸæœªæ»¡è¶³ï¼Œåªä¿ç•™æœªæ»¡è¶³çš„
                    # ä¾‹å¦‚: constraints = [C1, C2, C3], check = [True, False, True]
                    #       â†’ constraints = [C2] (åªä¿ç•™ C2)
                    current_constraint = [
                        current_constraint[i] 
                        for i in range(len(current_constraint)) 
                        if not check[i]  # ä¿ç•™ check[i] == False çš„çº¦æŸ
                    ]
                    all_constraint_types = [item[0] for item in current_constraint]
                
                # â”ˆâ”ˆâ”ˆâ”ˆâ”ˆ 4.5.5 åˆ¤æ–­æ˜¯å¦è¿›å…¥ç­‰å¾…çŠ¶æ€ â”ˆâ”ˆâ”ˆâ”ˆâ”ˆ
                # æ»¡è¶³æ¡ä»¶:
                #   1. æ‰€æœ‰çº¦æŸéƒ½æ»¡è¶³ (sum(check) == len(check))
                #   2. æˆ–è¶…è¿‡æœ€å¤§çº¦æŸæ­¥æ•° (constraint_steps >= max)
                if (sum(check) == len(check) or 
                    constraint_steps >= self.max_constraint_steps):
                    if not start_to_wait:
                        start_to_wait = True  # è¿›å…¥ç­‰å¾…çŠ¶æ€
                        self.constraints_check[current_idx] = True  # æ ‡è®°å­ä»»åŠ¡å®Œæˆ
                
                # â”ˆâ”ˆâ”ˆâ”ˆâ”ˆ 4.5.6 åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªå­ä»»åŠ¡ â”ˆâ”ˆâ”ˆâ”ˆâ”ˆ
                # æ»¡è¶³æ¡ä»¶:
                #   1. å·²è¿›å…¥ç­‰å¾…çŠ¶æ€ (start_to_wait == True)
                #   2. è¾¾åˆ°æœ€å°çº¦æŸæ­¥æ•° (constraint_steps >= min)
                # åŸå› : é¿å…å­ä»»åŠ¡åˆ‡æ¢è¿‡å¿«ï¼Œç¡®ä¿æ¯ä¸ªå­ä»»åŠ¡æ‰§è¡Œä¸€å®šæ—¶é—´
                if start_to_wait and (constraint_steps >= self.min_constraint_steps):
                    if False in self.constraints_check:
                        # è¿˜æœ‰æœªå®Œæˆçš„å­ä»»åŠ¡ï¼Œåˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ª
                        current_idx = self.constraints_check.index(False)
                        print(f"sub_instr_{current_idx}: {self.sub_instructions[current_idx]}")
                        
                        # æ›´æ–°æ–°å­ä»»åŠ¡çš„ç›®æ ‡ç±»åˆ«
                        landmarks = self.decisions[str(current_idx)]['landmarks']
                        if len(landmarks) > 0:
                            self.destination_class = [item[0] for item in landmarks]
                            self.classes = self._process_classes(
                                self.base_classes, self.destination_class
                            )
                        
                        # æ›´æ–°æ–°å­ä»»åŠ¡çš„çº¦æŸ
                        current_constraint = self.sub_constraints[str(current_idx)]
                        all_constraint_types = [item[0] for item in current_constraint]
                        
                        # é‡ç½®ä½å§¿æ£€æŸ¥ç‚¹
                        current_pose, start_check_pose = None, None
                    else:
                        # æ‰€æœ‰å­ä»»åŠ¡éƒ½å®Œæˆ
                        current_constraint, all_constraint_types = [], []
                        print("all constraints are done")
                    
                    # é‡ç½®çº¦æŸæ­¥æ•°å’Œç­‰å¾…æ ‡å¿—
                    constraint_steps = 0
                    start_to_wait = False
                    
            # æ‰“å°å½“å‰çŠ¶æ€ (è°ƒè¯•)
            print("current constraint: ", current_constraint)
            print("constraint_steps: ", constraint_steps)
                
            # â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            # â”‚ 4.6 æ›´æ–°å¯¼èˆªç›®æ ‡                                             â”‚
            # â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            # æ ¹æ®å½“å‰çº¦æŸæ›´æ–° self.destination (ç”¨äº BLIP æŸ¥è¯¢)
            
            # å¦‚æœæœ‰éæ–¹å‘çº¦æŸï¼Œä½¿ç”¨çº¦æŸä¸­çš„ landmark ä½œä¸ºç›®æ ‡
            if len(current_constraint) > 0 and current_constraint[0][0] != "direction constraint":
                new_destination = current_constraint[0][1]  # ä¾‹å¦‚: "kitchen"
                
                # å¦‚æœæ˜¯æœ€åä¸€ä¸ªå­ä»»åŠ¡ï¼Œä½¿ç”¨æœ€ç»ˆç›®æ ‡
                if current_idx >= len(self.sub_instructions) - 1:
                    self.destination = self.llm_reply['destination']  # LLMè§£æçš„æœ€ç»ˆç›®æ ‡
                else:
                    self.destination = new_destination  # å­ä»»åŠ¡çš„ä¸­é—´ç›®æ ‡
            
            # å¦‚æœæ‰€æœ‰çº¦æŸéƒ½å®Œæˆä¸”æ˜¯æœ€åä¸€ä¸ªå­ä»»åŠ¡ï¼Œä½¿ç”¨æœ€ç»ˆç›®æ ‡
            if len(current_constraint) == 0 and current_idx >= len(self.sub_constraints) - 1:
                self.destination = self.llm_reply['destination']
                
            # ç›®æ ‡å˜åŒ–æ—¶ï¼Œè¡°å‡ä»·å€¼å›¾ (é¿å…æ—§ç›®æ ‡çš„å½±å“)
            # ä¹˜ä»¥ 0.5: ä¿ç•™éƒ¨åˆ†å†å²ä¿¡æ¯ï¼Œä½†é™ä½å…¶æƒé‡
            if self.destination != self.last_destination:
                self.value_map_module.value_map[...] *= 0.5
                self.last_destination = self.destination
                
            # â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            # â”‚ 4.7 å¼‚å¸¸æ¢å¤: ä»·å€¼å›¾ä¸ºç©ºæ£€æµ‹                                 â”‚
            # â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            # ä»·å€¼å›¾ä¸ºç©ºè¡¨ç¤ºæ‰¾ä¸åˆ°å¯¼èˆªç›®æ ‡ï¼Œå¯èƒ½åŸå› :
            #   1. ç›®æ ‡ä¸åœ¨å½“å‰è§†é‡å†…
            #   2. ç›®æ ‡è¢«é®æŒ¡æˆ–æœªè¢«æ£€æµ‹åˆ°
            #   3. è¯­ä¹‰åˆ†å‰²å¤±è´¥
            
            # ç»Ÿè®¡ä»·å€¼å›¾ä¸­éé›¶åƒç´ æ•°é‡
            # é˜ˆå€¼: 24Ã—24 = 576 åƒç´  (çº¦ 1.2m Ã— 1.2m çš„åŒºåŸŸ)
            if np.sum(self.value_map_module.value_map[1].astype(bool)) <= 24**2:
                empty_value_map += 1  # è¿ç»­ä¸ºç©ºçš„æ¬¡æ•°
                constraint_steps = 0  # é‡ç½®çº¦æŸæ­¥æ•° (ä¸è®¡å…¥æ— æ•ˆæ­¥æ•°)
            else:
                empty_value_map = 0   # é‡ç½®è®¡æ•°å™¨
            
            # è¿ç»­ 5 æ¬¡ä¸ºç©ºï¼Œè§¦å‘é‡æ–°ç¯è§†
            if empty_value_map >= 5:
                print(f"[WARNING] Value map empty for {empty_value_map} steps, re-looking around...")
                full_pose, obs, dones, infos = self._look_around()  # é‡æ–°ç¯è§† 360Â°
                
                # æ£€æŸ¥ç¯è§†å episode æ˜¯å¦ç»“æŸ
                if dones[0]:
                    self._calculate_metric(infos)
                    break
                
                # é‡ç½®è®¡æ•°å™¨
                empty_value_map = 0
                constraint_steps = 0
            
            # â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            # â”‚ 4.8 æ‰§è¡ŒåŠ¨ä½œ                                                 â”‚
            # â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            actions = []
            for _ in range(self.config.NUM_ENVIRONMENTS):
                if self.keyboard_control:
                    # æ‰‹åŠ¨æ§åˆ¶æ¨¡å¼ (è°ƒè¯•ç”¨)
                    self._action2 = self._use_keyboard_control() 
                    actions.append(self._action2)
                else:
                    # ä½¿ç”¨ç­–ç•¥è§„åˆ’çš„åŠ¨ä½œ
                    # self._action åœ¨ä¸Šä¸€è½®çš„æœ€åæˆ– _look_around() ä¸­è®¡ç®—
                    actions.append(self._action)
            
            # åœ¨ä»¿çœŸç¯å¢ƒä¸­æ‰§è¡ŒåŠ¨ä½œ
            outputs = self.envs.step(actions)
            obs, _, dones, infos = [list(x) for x in zip(*outputs)]
            
            # Save RGB frames if print_images is enabled
            if self.config.MAP.PRINT_IMAGES:
                rgb_frame = obs[0]['rgb'].astype(np.uint8)  # Get RGB from observation
                save_dir = os.path.join(self.config.RESULTS_DIR, "rgb_frames/eps_%d"%self.current_episode_id)
                os.makedirs(save_dir, exist_ok=True)
                fn = "{}/step-{}.png".format(save_dir, step)
                # Convert RGB to BGR for OpenCV
                bgr_frame = cv2.cvtColor(rgb_frame, cv2.COLOR_RGB2BGR)
                cv2.imwrite(fn, bgr_frame)
            
            # â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            # â”‚ 4.9 æ£€æŸ¥ episode æ˜¯å¦ç»“æŸ                                   â”‚
            # â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            if dones[0]:
                # Episode ç»“æŸåŸå› å¯èƒ½æ˜¯:
                #   1. åˆ°è¾¾ç›®æ ‡ (Success)
                #   2. è¶…æ—¶ (è¾¾åˆ°æœ€å¤§æ­¥æ•° 500)
                #   3. è°ƒç”¨äº† STOP åŠ¨ä½œ
                self._calculate_metric(infos)  # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
                break  # é€€å‡ºå¯¼èˆªå¾ªç¯
            
            # â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            # â”‚ 4.10 æ›´æ–°è¯­ä¹‰åœ°å›¾                                            â”‚
            # â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            # å¤„ç†æ–°è§‚å¯Ÿ: RGB-D â†’ è¯­ä¹‰åˆ†å‰² â†’ ç‚¹äº‘ â†’ åœ°å›¾æŠ•å½±
            batch_obs = self._batch_obs(obs)  # é¢„å¤„ç†è§‚å¯Ÿ (åŒ…å« GroundedSAM åˆ†å‰²)
            
            # è·å–ç›¸å¯¹ä½å§¿å˜åŒ–
            poses = torch.from_numpy(
                np.array([item['sensor_pose'] for item in obs])
            ).float().to(self.device)  # [Î”x, Î”y, Î”Î¸]
            
            # è°ƒç”¨ Mapping æ¨¡å—å‰å‘ä¼ æ’­
            self.mapping_module(batch_obs, poses)
            
            # æ›´æ–°å…¨å±€åœ°å›¾å¹¶è·å–å½“å‰çŠ¶æ€
            full_map, full_pose, one_step_full_map = \
                self.mapping_module.update_map(step, self.detected_classes, self.current_episode_id)
            
            # æ¸…ç©ºå•æ­¥åœ°å›¾ (å‡†å¤‡ä¸‹ä¸€æ­¥)
            self.mapping_module.one_step_full_map.fill_(0.)
            self.mapping_module.one_step_local_map.fill_(0.)
            
            # â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            # â”‚ 4.11 å¤„ç†å¯¼èˆªåœ°å›¾ (æå–å¯å¯¼èˆªä¿¡æ¯)                           â”‚
            # â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            # ä»è¯­ä¹‰åœ°å›¾ä¸­æå–:
            #   - traversible: å¯ç©¿è¶ŠåŒºåŸŸ (æ— éšœç¢ç‰©å’Œä¸å¯å¯¼èˆªç‰©ä½“)
            #   - floor: åœ°æ¿åŒºåŸŸ (å¯è¡Œèµ°çš„å¹³é¢)
            #   - frontiers: æ¢ç´¢è¾¹ç•Œ (å·²æ¢ç´¢åŒºåŸŸçš„è½®å»“)
            self.traversible, self.floor, self.frontiers = self._process_map(step, full_map[0])
            
            # Save floor map visualization if print_images is enabled
            if self.config.MAP.PRINT_IMAGES:
                self._save_floor_semantic_map(step, self.current_episode_id, full_map[0])
            
            # å¤„ç†å½“å‰æ­¥æ–°æ¢ç´¢çš„åœ°æ¿ (ç”¨äºä»·å€¼å›¾çš„æ¢ç´¢å¥–åŠ±)
            self.one_step_floor = self._process_one_step_floor(one_step_full_map[0])
            
            # â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            # â”‚ 4.12 å¼‚å¸¸æ¢å¤: ç¢°æ’æ£€æµ‹ä¸å¡ä½å¤„ç†                            â”‚
            # â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            # æ£€æµ‹æ™ºèƒ½ä½“æ˜¯å¦è¢«å¡ä½ (è¿ç»­å¤šæ­¥ä½ç§»å¾ˆå°)
            
            # ä¿å­˜ä¸Šä¸€æ­¥ä½å§¿
            last_pose = current_pose
            current_pose = full_pose[0]  # æ›´æ–°å½“å‰ä½å§¿
            
            if last_pose is not None and current_pose is not None:
                # è®¡ç®—ä¸¤æ­¥ä¹‹é—´çš„ä½ç§» (æ¬§æ°è·ç¦»ï¼Œå•ä½: åƒç´ )
                displacement = calculate_displacement(last_pose, current_pose, self.resolution)
                
                # é˜ˆå€¼: 0.2m = 20cm = 4 åƒç´  (5cm/åƒç´ )
                # å¦‚æœä½ç§» < 0.2mï¼Œè®¤ä¸ºæ˜¯å¡ä½æˆ–ç¢°æ’
                if displacement < 0.2 * 100 / self.resolution:  # 0.2m â†’ 4 pixels
                    collided += 1  # ç´¯è®¡å¡ä½æ­¥æ•°
                else:
                    # ç§»åŠ¨æ­£å¸¸ï¼Œé‡ç½®è®¡æ•°å™¨
                    collided = 0
                    replan = False
                
                # è¿ç»­å¡ä½ 30 æ­¥ï¼Œè§¦å‘é‡æ–°è§„åˆ’
                if collided >= 30:
                    replan = True  # å‘Šè¯‰ policy å¼ºåˆ¶é‡æ–°è§„åˆ’è·¯å¾„
                    print(f"[WARNING] {self.current_episode_id}: Stuck for {collided} steps\n")
                    
                    # è®°å½•æ—¥å¿— (è°ƒè¯•ç”¨)
                    fname = os.path.join(
                        self.config.EVAL_CKPT_PATH_DIR, 
                        f"r{self.local_rank}_w{self.world_size}_collision_stuck.txt"
                    )
                    with open(fname, "a") as f:
                        f.writelines(
                            f"id: {str(self.current_episode_id)}; "
                            f"step: {str(step)}; "
                            f"collided: {str(collided)}\n"
                        )
                
            # â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            # â”‚ 4.13 æ›´æ–°ç¢°æ’åœ°å›¾                                            â”‚
            # â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            # åªåœ¨æ‰§è¡Œ FORWARD åŠ¨ä½œæ—¶æ›´æ–°ç¢°æ’åœ°å›¾
            # åŸå› : TURN_LEFT/TURN_RIGHT ä¸ä¼šäº§ç”Ÿç¢°æ’
            
            last_action = current_action
            current_action = self._action
            
            if last_pose is not None and current_action["action"] == 1:  # 1 = MOVE_FORWARD
                # ä½¿ç”¨ FMM ç®—æ³•æ£€æµ‹ä» last_pose åˆ° current_pose çš„è·¯å¾„ä¸Šæ˜¯å¦æœ‰ç¢°æ’
                # åŸç†: å¦‚æœè§„åˆ’çš„è·¯å¾„å’Œå®é™…ä½ç§»ä¸ç¬¦ï¼Œè¯´æ˜å‘ç”Ÿäº†ç¢°æ’
                collision_map = collision_check_fmm(
                    last_pose, 
                    current_pose, 
                    self.resolution, 
                    self.mapping_module.map_shape
                )
                
                # ç´¯ç§¯ç¢°æ’åœ°å›¾ (é€»è¾‘æˆ–è¿ç®—)
                # ä¸€æ—¦æŸä¸ªä½ç½®è¢«æ ‡è®°ä¸ºç¢°æ’ï¼Œåç»­ä¼šæŒç»­é¿å¼€
                self.collision_map = np.logical_or(self.collision_map, collision_map)
            
            # â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            # â”‚ 4.14 è®¡ç®—ä»·å€¼å›¾ (BLIP è§†è§‰-è¯­è¨€åŒ¹é…)                         â”‚
            # â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            # BLIP (Bootstrapped Language-Image Pre-training):
            #   - è¾“å…¥: RGB å›¾åƒ + ç›®æ ‡æ–‡æœ¬ (å¦‚ "kitchen")
            #   - è¾“å‡º: æ¯ä¸ªåƒç´ ä¸ç›®æ ‡çš„è¯­ä¹‰ç›¸ä¼¼åº¦ [0, 1]
            #   - åŸç†: è§†è§‰-è¯­è¨€å¯¹æ¯”å­¦ä¹ 
            
            blip_value = self.value_map_module.get_blip_value(
                Image.fromarray(obs[0]['rgb']),  # å½“å‰ RGB è§‚å¯Ÿ
                self.destination                 # ç›®æ ‡æè¿°
            )
            blip_value = blip_value.detach().cpu().numpy()  # (160, 160)
            
            # èåˆå¤šç§ä¿¡æ¯ç”Ÿæˆä»·å€¼å›¾
            # è¾“å…¥:
            #   - blip_value: BLIP è¯­ä¹‰ç›¸ä¼¼åº¦
            #   - full_map: è¯­ä¹‰åœ°å›¾ (ç›®æ ‡ç±»åˆ«çš„æ©ç )
            #   - floor: åœ°æ¿åŒºåŸŸ
            #   - one_step_floor: æ–°æ¢ç´¢åŒºåŸŸ
            #   - collision_map: ç¢°æ’åŒºåŸŸ
            # è¾“å‡º:
            #   - value_map[0]: åŸå§‹ä»·å€¼å›¾
            #   - value_map[1]: å¤„ç†åä»·å€¼å›¾ (ä¼šåœ¨ä¸‹ä¸€æ­¥ä¹˜ä»¥ history_map å’Œ direction_map)
            value_map = self.value_map_module(
                step, 
                full_map[0], 
                self.floor, 
                self.one_step_floor, 
                self.collision_map, 
                blip_value, 
                full_pose[0], 
                self.detected_classes, 
                self.current_episode_id
            )
            
            # â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            # â”‚ 4.15 è·¯å¾„è§„åˆ’ (FMM ç®—æ³•)                                     â”‚
            # â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            # Fast Marching Method (FMM):
            #   â‘  å°†ä»·å€¼å›¾ä½œä¸ºç›®æ ‡åœº (é«˜ä»·å€¼åŒºåŸŸ = ç›®æ ‡)
            #   â‘¡ FMM æ‰©æ•£ç®—æ³•è®¡ç®—è·ç¦»åœº (æ¯ä¸ªä½ç½®åˆ°é«˜ä»·å€¼åŒºåŸŸçš„è·ç¦»)
            #   â‘¢ æ¢¯åº¦ä¸‹é™æ‰¾åˆ°æœ€ä¼˜è·¯å¾„
            #   â‘£ æ ¹æ®è·¯å¾„æ–¹å‘ç”ŸæˆåŠ¨ä½œ
            
            # èåˆçº¦æŸåœ°å›¾
            # value_map[1] * history_map * direction_map
            #   - history_map: é™ä½å·²è®¿é—®åŒºåŸŸçš„ä»·å€¼
            #   - direction_map: å±è”½ä¸ç¬¦åˆæ–¹å‘çº¦æŸçš„åŒºåŸŸ (å¦‚æœæœ‰)
            final_value_map = self.value_map_module.value_map[1] * history_map
            
            # æ³¨æ„: direction_map åœ¨å½“å‰å®ç°ä¸­æœªç›´æ¥ä¹˜å…¥ï¼Œè€Œæ˜¯åœ¨ policy ä¸­å¤„ç†
            # å¦‚æœéœ€è¦åº”ç”¨æ–¹å‘çº¦æŸï¼Œå¯ä»¥å–æ¶ˆä¸‹é¢è¿™è¡Œçš„æ³¨é‡Š:
            # final_value_map = final_value_map * direction_map
            
            self._action = self.policy(
                final_value_map,              # èåˆåçš„ä»·å€¼å›¾ (480, 480)
                self.collision_map,           # ç¢°æ’åœ°å›¾ (480, 480)
                full_map[0],                  # å®Œæ•´è¯­ä¹‰åœ°å›¾ (N+4, 480, 480)
                self.floor,                   # åœ°æ¿åŒºåŸŸ (480, 480)
                self.traversible,             # å¯ç©¿è¶ŠåŒºåŸŸ (480, 480)
                full_pose[0],                 # å½“å‰ä½å§¿ [x, y, heading]
                self.frontiers,               # æ¢ç´¢è¾¹ç•Œ (480, 480)
                self.detected_classes,        # å·²æ£€æµ‹ç±»åˆ«åˆ—è¡¨
                self.destination_class,       # ç›®æ ‡ç±»åˆ«åˆ—è¡¨
                self.classes,                 # å½“å‰è¦æ£€æµ‹çš„ç±»åˆ«åˆ—è¡¨
                search_destination,           # æ˜¯å¦æœç´¢æœ€ç»ˆç›®æ ‡
                one_step_full_map[0],        # å½“å‰å¸§åœ°å›¾ (N+4, 480, 480)
                self.current_detections,      # å½“å‰æ£€æµ‹ç»“æœ
                self.current_episode_id,      # episode ID (ç”¨äºå¯è§†åŒ–)
                replan,                       # æ˜¯å¦å¼ºåˆ¶é‡æ–°è§„åˆ’
                step                          # å½“å‰æ­¥æ•°
            )
            # self._action = {"action": 0/1/2/3}
            #   0 = STOP (åˆ°è¾¾ç›®æ ‡æˆ–æ”¾å¼ƒ)
            #   1 = MOVE_FORWARD (å‰è¿›)
            #   2 = TURN_LEFT (å·¦è½¬ 30Â°)
            #   3 = TURN_RIGHT (å³è½¬ 30Â°)
    
    def eval(self):
        """è¯„ä¼°ä¸»å‡½æ•°
        
        æµç¨‹ï¼š
        1. è®¾ç½®è¯„ä¼°é…ç½®
        2. åˆå§‹åŒ–ç¯å¢ƒ
        3. åŠ è½½çœŸå®è½¨è¿¹
        4. åˆå§‹åŒ–ç­–ç•¥æ¨¡å—
        5. å¾ªç¯è¯„ä¼°æ¯ä¸ª episode
        6. ä¿å­˜ç»“æœåˆ° JSON
        """
        # ===== åˆå§‹åŒ– =====
        self._set_eval_config()  # è®¾ç½®é…ç½®
        self._init_envs()  # åˆå§‹åŒ– Habitat ç¯å¢ƒ
        self._collect_val_traj()  # åŠ è½½çœŸå®è½¨è¿¹ï¼ˆç”¨äºè®¡ç®— NDTWï¼‰
        self._initialize_policy()  # åˆå§‹åŒ–æ‰€æœ‰ç­–ç•¥æ¨¡å—
        
        # ===== ç¡®å®šè¦è¯„ä¼°çš„ episode æ•°é‡ =====
        if self.config.EVAL.EPISODE_COUNT == -1:
            eps_to_eval = sum(self.envs.number_of_episodes)  # è¯„ä¼°æ‰€æœ‰åˆ†é…çš„ episodes
        else:
            eps_to_eval = min(self.config.EVAL.EPISODE_COUNT, sum(self.envs.number_of_episodes))
            
        # ===== å¾ªç¯è¯„ä¼°æ¯ä¸ª episode =====
        self.state_eps = {}  # å­˜å‚¨æ¯ä¸ª episode çš„è¯„ä¼°ç»“æœ
        t1 = time.time()
        for i in tqdm(range(eps_to_eval)):
            self.rollout()  # æ‰§è¡Œä¸€ä¸ªå®Œæ•´ episode
            self.reset()  # é‡ç½®çŠ¶æ€
                    
        self.envs.close()
        
        # ===== ä¿å­˜ç»“æœ =====
        split = self.config.TASK_CONFIG.DATASET.SPLIT
        fname = os.path.join(self.config.EVAL_CKPT_PATH_DIR, 
                             f"stats_ep_ckpt_{split}_r{self.local_rank}_w{self.world_size}.json"
                             )
        with open(fname, "w") as f:
            json.dump(self.state_eps, f, indent=2)
        t2 = time.time()
        logger.info(f"time: {t2 - t1}s")
        print("test time: ", t2 - t1)